

@article{Altenkirch2015-yl,
  title     = {Indexed containers},
  author    = {Altenkirch, Thorsten and Ghani, Neil and Hancock, Peter and
               Mcbride, Conor and Morris, Peter},
  abstract  = {We show that the syntactically rich notion of strictly positive
               families can be reduced to a core type theory with a fixed
               number of type constructors exploiting the novel notion of
               indexed containers. As a result, we show indexed containers
               provide normal forms for strictly positive families in much the
               same way that containers provide normal forms for strictly
               positive types. Interestingly, this step from containers to
               indexed containers is achieved without having to extend the core
               type theory. Most of the construction presented here has been
               formalized using the Agda system.},
  journal   = {J. Funct. Programming},
  publisher = {Cambridge University Press},
  volume    = 25,
  pages     = {e5},
  month     = jan,
  year      = 2015
}

@inproceedings{Boulier2017-cm,
  title     = {The next 700 syntactical models of type theory},
  booktitle = {Proceedings of the 6th {ACM} {SIGPLAN} Conference on Certified
               Programs and Proofs},
  author    = {Boulier, Simon and P{\'e}drot, Pierre-Marie and Tabareau,
               Nicolas},
  abstract  = {A family of syntactic models for the calculus of construction
               with universes (CC$\omega$) is described, all of them preserving
               conversion of the calculus definitionally, and thus giving rise
               directly to a program transformation of CC$\omega$ into itself.
               Those models are based on the remark that negative type
               constructors (e.g. dependent product, coinductive types or
               universes) are underspecified in type theory-which leaves some
               freedom on extra intensional specifications. The model
               construction can be seen as a compilation phase from a complex
               type theory into a simpler type theory. Such models can be used
               to derive (the negative part of) independence results with
               respect to CC$\omega$, such as functional extensionality,
               propositional extensionality, univalence or the fact that
               bisimulation on a coinductive type may not coincide with
               equality. They can also be used to add new principles to the
               theory, which we illustrate by defining a version of CC$\omega$
               with ad-hoc polymorphism that shows in particular that
               parametricity is not an implicit requirement of type theory. The
               correctness of some of the models/program transformations have
               been checked in the Coq proof assistant and have been
               instrumented as a Coq plugin.},
  publisher = {Association for Computing Machinery},
  pages     = {182--194},
  series    = {CPP 2017},
  month     = jan,
  year      = 2017,
  address   = {New York, NY, USA},
  keywords  = {Dependent type theory, Program translation},
  location  = {Paris, France}
}

@article{Boulier2018-zy,
  title    = {Extending type theory with syntactic models},
  author   = {Boulier, S},
  abstract = {This thesis is about the metatheory of intuitionnistic type
              theory. The considered systems are variants of Martin-Lof type
              theory of Calculus of Constructions, and we are interested in the
              coherence of those systems and in the independence of axioms with
              respect to those systems. The common theme of this thesis is the
              construction of syntactic models, which are models reusing type
              theory to interpret type theory. In a first part, we introduce
              type theory by a minimal system and several possible extensions.
              In a second part, we introduce the syntactic models given by
              program translation and give several examples. In a third part,
              we present Template-Coq, a plugin for metaprogramming in Coq. We
              demonstrate how to use it to implement directly some syntactic
              models. Last, we consider type theories with two equalities: one
              strict and one univalent. We propose a re-reading of works of
              Coquand et.al. and of Orton and Pitts on the cubical model by
              introducing degenerate fibrancy.},
  month    = nov,
  year     = 2018
}

@article{Hewer2024-cc,
  title     = {Quotient Haskell: Lightweight Quotient Types for All},
  author    = {Hewer, Brandon and Hutton, Graham},
  abstract  = {Subtypes and quotient types are dual type abstractions. However,
               while subtypes are widely used both explicitly and implicitly,
               quotient types have not seen much practical use outside of proof
               assistants. A key difficulty to wider adoption of quotient types
               lies in the significant burden of proof-obligations that arises
               from their use. In this article, we address this issue by
               introducing a class of quotient types for which the
               proof-obligations are decidable by an SMT solver. We demonstrate
               this idea in practice by presenting Quotient Haskell, an
               extension of Liquid Haskell with support for quotient types.},
  journal   = {Proc. ACM Program. Lang.},
  publisher = {Association for Computing Machinery},
  volume    = 8,
  number    = {POPL},
  pages     = {785--815},
  month     = jan,
  year      = 2024,
  address   = {New York, NY, USA},
  keywords  = {quotient types, refinement types, static verification}
}

@inproceedings{Viera2006-xq,
  title     = {A multi-stage language with intensional analysis},
  booktitle = {{GPCE} '06: Proceedings of the 5th International Conference on
               Generative Programming and Component Engineering},
  author    = {Viera, Marcos and Pardo, Alberto},
  abstract  = {This paper presents the definition of a language with reflection
               primitives. The language is a homogeneous multi-stage language
               that provides the capacity of code analysis by the inclusion of
               a pattern matching mechanism that permits inspection of the
               structure of quoted expressions and their destruction into
               component subparts. Quoted expressions include an explicit
               annotation of their context which is used for dynamic inference
               of type, where a dynamic typing discipline based on Hinze and
               Cheney's approach is used for typing quoted expressions.This
               paper follows the approach of Sheard and Pasalic about the use
               of the meta-language $\Omega$mega as a tool for language design.
               In this sense, it is shown how to represent the syntax, the
               static as well as the dynamic semantics of the proposed language
               in terms of $\Omega$mega constructs.},
  publisher = {unknown},
  month     = oct,
  year      = 2006
}

@article{Kovacs2022-vb,
  title         = {Staged compilation with two-level type theory},
  author        = {Kov{\'a}cs, Andr{\'a}s},
  abstract      = {The aim of staged compilation is to enable metaprogramming
                   in a way such that we have guarantees about the
                   well-formedness of code output, and we can also mix together
                   object-level and meta-level code in a concise and convenient
                   manner. In this work, we observe that two-level type theory
                   (2LTT), a system originally devised for the purpose of
                   developing synthetic homotopy theory, also serves as a
                   system for staged compilation with dependent types. 2LTT has
                   numerous good properties for this use case: it has a concise
                   specification, well-behaved model theory, and it supports a
                   wide range of language features both at the object and the
                   meta level. First, we give an overview of 2LTT's features
                   and applications in staging. Then, we present a staging
                   algorithm and prove its correctness. Our algorithm is
                   ``staging-by-evaluation'', analogously to the technique of
                   normalization-by-evaluation, in that staging is given by the
                   evaluation of 2LTT syntax in a semantic domain. The staging
                   algorithm together with its correctness constitutes a proof
                   of strong conservativity of 2LLT over the object theory. To
                   our knowledge, this is the first description of staged
                   compilation which supports full dependent types and
                   unrestricted staging for types.},
  month         = sep,
  year          = 2022,
  archiveprefix = {arXiv},
  primaryclass  = {cs.PL},
  eprint        = {2209.09729}
}

@article{Yallop2017-cg,
  title     = {Staged generic programming},
  author    = {Yallop, Jeremy},
  abstract  = {Generic programming libraries such as Scrap Your Boilerplate
               eliminate the need to write repetitive code, but typically
               introduce significant performance overheads. This leaves
               programmers with the regrettable choice between writing succinct
               but slow programs and writing tedious but efficient programs.
               Applying structured multi-stage programming techniques
               transforms Scrap Your Boilerplate from an inefficient library
               into a typed optimising code generator, bringing its performance
               in line with hand-written code, and so combining high-level
               programming with uncompromised performance.},
  journal   = {Proc. ACM Program. Lang.},
  publisher = {Association for Computing Machinery},
  volume    = 1,
  number    = {ICFP},
  pages     = {1--29},
  month     = aug,
  year      = 2017,
  address   = {New York, NY, USA},
  keywords  = {generic programming, metaprogramming, multi-stage programming,
               partial evaluation}
}

@article{Castellan2019-sh,
  title         = {Categories with Families: Unityped, Simply Typed, and
                   Dependently Typed},
  author        = {Castellan, Simon and Clairambault, Pierre and Dybjer, Peter},
  abstract      = {We show how the categorical logic of untyped, simply typed
                   and dependently typed lambda calculus can be structured
                   around the notion of category with family (cwf). To this end
                   we introduce subcategories of simply typed cwfs (scwfs),
                   where types do not depend on variables, and unityped cwfs
                   (ucwfs), where there is only one type. We prove several
                   equivalence and biequivalence theorems between cwf-based
                   notions and basic notions of categorical logic, such as
                   cartesian operads, Lawvere theories, categories with finite
                   products and limits, cartesian closed categories, and
                   locally cartesian closed categories. Some of these theorems
                   depend on the restrictions of contextuality (in the sense of
                   Cartmell) or democracy (used by Clairambault and Dybjer for
                   their biequivalence theorems). Some theorems are
                   equivalences between notions with strict preservation of
                   chosen structure. Others are biequivalences between notions
                   where properties are only preserved up to isomorphism. In
                   addition to this we discuss various constructions of initial
                   ucwfs, scwfs, and cwfs with extra structure.},
  month         = apr,
  year          = 2019,
  archiveprefix = {arXiv},
  primaryclass  = {cs.LO},
  eprint        = {1904.00827}
}

@misc{Yallop_undated-sh,
  title        = {Unembedding {Domain-Specific} Languages},
  author       = {Yallop, Robert Atkey Sam Lindley},
  howpublished = {\url{https://bentnib.org/unembedding.pdf}},
  note         = {Accessed: 2024-2-22}
}

@article{Sato2001-ap,
  title   = {A simply typed context calculus with first-class environments},
  author  = {Sato, M and Sakurai, Takafumi and Kameyama, Yukiyoshi},
  journal = {J. Funct. Log. Prog.},
  pages   = {359--374},
  month   = mar,
  year    = 2001
}

@article{Brady2010-sf,
  title     = {Scrapping your inefficient engine: using partial evaluation to
               improve domain-specific language implementation},
  author    = {Brady, Edwin C and Hammond, Kevin},
  abstract  = {Partial evaluation aims to improve the efficiency of a program
               by specialising it with respect to some known inputs. In this
               paper, we show that partial evaluation can be an effective and,
               unusually, easy to use technique for the efficient
               implementation of embedded domain-specific languages. We achieve
               this by exploiting dependent types and by following some simple
               rules in the definition of the interpreter for the
               domain-specific language. We present experimental evidence that
               partial evaluation of programs in domain-specific languages can
               yield efficient residual programs whose performance is
               competitive with their Java and C equivalents and which are
               also, through the use of dependent types, verifiably
               resource-safe. Using our technique, it follows that a verifiably
               correct and resource-safe program can also be an efficient
               program},
  journal   = {SIGPLAN Not.},
  publisher = {Association for Computing Machinery},
  volume    = 45,
  number    = 9,
  pages     = {297--308},
  month     = sep,
  year      = 2010,
  address   = {New York, NY, USA},
  keywords  = {dependent types, partial evaluation}
}


@article{Annenkov2017-pd,
  title         = {{Two-Level} Type Theory and Applications},
  author        = {Annenkov, Danil and Capriotti, Paolo and Kraus, Nicolai and
                   Sattler, Christian},
  abstract      = {We define and develop two-level type theory (2LTT), a
                   version of Martin-L\textbackslash``of type theory which
                   combines two different type theories. We refer to them as
                   the inner and the outer type theory. In our case of
                   interest, the inner theory is homotopy type theory (HoTT)
                   which may include univalent universes and higher inductive
                   types. The outer theory is a traditional form of type theory
                   validating uniqueness of identity proofs (UIP). One point of
                   view on it is as internalised meta-theory of the inner type
                   theory. There are two motivations for 2LTT. Firstly, there
                   are certain results about HoTT which are of meta-theoretic
                   nature, such as the statement that semisimplicial types up
                   to level $n$ can be constructed in HoTT for any externally
                   fixed natural number $n$. Such results cannot be expressed
                   in HoTT itself, but they can be formalised and proved in
                   2LTT, where $n$ will be a variable in the outer theory. This
                   point of view is inspired by observations about
                   conservativity of presheaf models. Secondly, 2LTT is a
                   framework which is suitable for formulating additional
                   axioms that one might want to add to HoTT. This idea is
                   heavily inspired by Voevodsky's Homotopy Type System (HTS),
                   which constitutes one specific instance of a 2LTT. HTS has
                   an axiom ensuring that the type of natural numbers behaves
                   like the external natural numbers, which allows the
                   construction of a universe of semisimplicial types. In 2LTT,
                   this axiom can be stated simply be asking the inner and
                   outer natural numbers to be isomorphic. After defining 2LTT,
                   we set up a collection of tools with the goal of making 2LTT
                   a convenient language for future developments. As a first
                   such application, we develop the theory of Reedy fibrant
                   diagrams in the style of Shulman. Continuing this line of
                   thought, we suggest a definition of (infinity,1)-category
                   and give some examples.},
  month         = may,
  year          = 2017,
  archiveprefix = {arXiv},
  primaryclass  = {cs.LO},
  eprint        = {1705.03307}
}

@inproceedings{Taha1997-ag,
  title     = {Multi-stage programming with explicit annotations},
  booktitle = {Proceedings of the 1997 {ACM} {SIGPLAN} symposium on Partial
               evaluation and semantics-based program manipulation},
  author    = {Taha, Walid and Sheard, Tim},
  abstract  = {We introduce MetaML, a statically-typed multi-stage programming
               language extending Nielson and Nielson's two stage notation to
               an arbitrary number of stages. MetaML extends previous work by
               introducing four distinct staging annotations which generalize
               those published previously [25, 12, 7, 6]We give a static
               semantics in which type checking is done once and for all before
               the first stage, and a dynamic semantics which introduces a new
               concept of cross-stage persistence, which requires that
               variables available in any stage are also available in all
               future stages.We illustrate that staging is a manual form of
               binding time analysis. We explain why, even in the presence of
               automatic binding time analysis, explicit annotations are
               useful, especially for programs with more than two stages.A
               thesis of this paper is that multi-stage languages are useful as
               programming languages in their own right, and should support
               features that make it possible for programmers to write staged
               computations without significantly changing their normal
               programming style. To illustrate this we provide a simple three
               stage example, and an extended two-stage example elaborating a
               number of practical issues.},
  publisher = {Association for Computing Machinery},
  pages     = {203--217},
  series    = {PEPM '97},
  month     = dec,
  year      = 1997,
  address   = {New York, NY, USA},
  location  = {Amsterdam, The Netherlands}
}


@article{Uemura2019-cc,
  title    = {A General Framework for the Semantics of Type Theory},
  author   = {Uemura, Taichi},
  abstract = {We propose an abstract notion of a type theory to unify the
              semantics of various type theories including
              Martin-L\textbackslash``\{o\}f type theory, two-level type theory
              and cubical type theory. We establish basic results in the
              semantics of type theory: every type theory has a bi-initial
              model; every model of a type theory has its internal language;
              the category of theories over a type theory is bi-equivalent to a
              full sub-2-category of the 2-category of models of the type
              theory.},
  journal  = {arXiv [math.CT]},
  month    = apr,
  year     = 2019
}


@article{Awodey2014-hh,
  title         = {Natural models of homotopy type theory},
  author        = {Awodey, Steve},
  abstract      = {The notion of a natural model of type theory is defined in
                   terms of that of a representable natural transfomation of
                   presheaves. It is shown that such models agree exactly with
                   the concept of a category with families in the sense of
                   Dybjer, which can be regarded as an algebraic formulation of
                   type theory. We determine conditions for such models to
                   satisfy the inference rules for dependent sums, dependent
                   products, and intensional identity types, as used in
                   homotopy type theory. It is then shown that a category
                   admits such a model if it has a class of maps that behave
                   like the abstract fibrations in axiomatic homotopy theory:
                   they should be stable under pullback, closed under
                   composition and relative products, and there should be
                   weakly orthogonal factorizations into the class. It follows
                   that many familiar settings for homotopy theory also admit
                   natural models of the basic system of homotopy type theory.},
  month         = jun,
  year          = 2014,
  archiveprefix = {arXiv},
  primaryclass  = {math.CT},
  eprint        = {1406.3219}
}


@article{Baudon2023-cy,
  title     = {{Bit-Stealing} Made Legal: Compilation for Custom Memory
               Representations of Algebraic Data Types},
  author    = {Baudon, Tha{\"\i}s and Radanne, Gabriel and Gonnord, Laure},
  abstract  = {Initially present only in functional languages such as OCaml and
               Haskell, Algebraic Data Types (ADTs) have now become pervasive
               in mainstream languages, providing nice data abstractions and an
               elegant way to express functions through pattern matching.
               Unfortunately, ADTs remain seldom used in low-level programming.
               One reason is that their increased convenience comes at the cost
               of abstracting away the exact memory layout of values. Even
               Rust, which tries to optimize data layout, severely limits
               control over memory representation. In this article, we present
               a new approach to specify the data layout of rich data types
               based on a dual view: a source type, providing a high-level
               description available in the rest of the code, along with a
               memory type, providing full control over the memory layout. This
               dual view allows for better reasoning about memory layout, both
               for correctness, with dedicated validity criteria linking the
               two views, and for optimizations that manipulate the memory
               view. We then provide algorithms to compile constructors and
               destructors, including pattern matching, to their low-level
               memory representation. We prove our compilation algorithms
               correct, implement them in a tool called ribbit that compiles to
               LLVM IR, and show some early experimental results.},
  journal   = {Proc. ACM Program. Lang.},
  publisher = {Association for Computing Machinery},
  volume    = 7,
  number    = {ICFP},
  pages     = {813--846},
  month     = aug,
  year      = 2023,
  address   = {New York, NY, USA},
  keywords  = {Algebraic Data Types, Compilation, Data Layouts, Pattern
               Matching}
}

@inproceedings{Hinze2011-jx,
  title     = {Type Fusion},
  booktitle = {Algebraic Methodology and Software Technology},
  author    = {Hinze, Ralf},
  abstract  = {Fusion is an indispensable tool in the arsenal of techniques for
               program derivation. Less well-known, but equally valuable is
               type fusion, which states conditions for fusing an application
               of a functor with an initial algebra to form another initial
               algebra. We provide a novel proof of type fusion based on
               adjoint folds and discuss several applications: type
               firstification, type specialisation and tabulation.},
  publisher = {Springer Berlin Heidelberg},
  pages     = {92--110},
  year      = 2011
}

@inproceedings{Shao1994-kp,
  title     = {Unrolling lists},
  booktitle = {Proceedings of the 1994 {ACM} conference on {LISP} and
               functional programming},
  author    = {Shao, Zhong and Reppy, John H and Appel, Andrew W},
  abstract  = {Lists are ubiquitous in functional programs, thus supporting
               lists efficiently is a major concern to compiler writers for
               functional languages. Lists are normally represented as linked
               cons cells, with each cons cell containing a car (the data) and
               a cdr (the link); this is inefficient in the use of space,
               because 50\% of the storage is used for links. Loops and
               recursions on lists are slow on modern machines because of the
               long chains of control dependencies (in checking for nil) and
               data dependencies (in fetching cdr fields).We present a data
               structure for ``unrolled lists'', where each cell has several
               data items (car fields) and one link (cdr). This reduces the
               memory used for links, and it significantly shortens the length
               of control-dependence and data-dependence chains in operations
               on lists.We further present an efficient compile-time analysis
               that transforms programs written for ``ordinary'' lists into
               programs on unrolled lists. The use of our new representation
               requires no change to existing programs.We sketch the proof of
               soundness of our analysis---which is based on refinement
               types---and present some preliminary measurements of our
               technique.},
  publisher = {Association for Computing Machinery},
  pages     = {185--195},
  series    = {LFP '94},
  month     = jul,
  year      = 1994,
  address   = {New York, NY, USA},
  location  = {Orlando, Florida, USA}
}

@misc{Kaposi2020-is,
  title     = {A syntax for mutual inductive families},
  author    = {Kaposi, Ambrus and von Raumer, Jakob},
  abstract  = {Inductive families of types are a feature of most languages
               based on dependent types. They are usually described either by
               syntactic schemes or by encodings of strictly positive functors
               such as combinator languages or containers. The former
               approaches are informal and give only external signatures, the
               latter approaches suffer from encoding overheads and do not
               directly represent mutual types. In this paper we propose a
               direct method for describing signatures for mutual inductive
               families using a domain-specific type theory. A signature is a
               context (roughly speaking, a list of types) in this small type
               theory. Algebras, displayed algebras and sections are defined by
               models of this type theory: the standard model, the logical
               predicate and a logical relation interpretation, respectively.
               We reduce the existence of initial algebras for these signatures
               to the existence of the syntax of our domain-specific type
               theory. As this theory is very simple, its normal syntax can be
               encoded using indexed W-types. To the best of our knowledge,
               this is the first formalisation of the folklore fact that mutual
               inductive types can be reduced to indexed W-types. The contents
               of this paper were formalised in the proof assistant Agda.},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"u}r Informatik},
  month     = jun,
  year      = 2020
}


@inproceedings{Allais2023-pf,
  title     = {Builtin Types Viewed as Inductive Families},
  booktitle = {Programming Languages and Systems},
  author    = {Allais, Guillaume},
  abstract  = {State of the art optimisation passes for dependently typed
               languages can help erase the redundant information typical of
               invariant-rich data structures and programs. These automated
               processes do not dramatically change the structure of the data,
               even though more efficient representations could be available.},
  publisher = {Springer Nature Switzerland},
  pages     = {113--139},
  year      = 2023
}

@article{Allais2023-zq,
  title         = {Seamless, Correct, and Generic Programming over Serialised
                   Data},
  author        = {Allais, Guillaume},
  abstract      = {In typed functional languages, one can typically only
                   manipulate data in a type-safe manner if it first has been
                   deserialised into an in-memory tree represented as a graph
                   of nodes-as-structs and subterms-as-pointers. We demonstrate
                   how we can use QTT as implemented in \textbackslashidris\{\}
                   to define a small universe of serialised datatypes, and
                   provide generic programs allowing users to process values
                   stored contiguously in buffers. Our approach allows
                   implementors to prove the full functional correctness by
                   construction of the IO functions processing the data stored
                   in the buffer.},
  month         = oct,
  year          = 2023,
  archiveprefix = {arXiv},
  primaryclass  = {cs.PL},
  eprint        = {2310.13441}
}


@article{Dybjer1994-zx,
  title     = {Inductive families},
  author    = {Dybjer, Peter},
  abstract  = {A general formulation of inductive and recursive definitions in
               Martin-L{\"o}f's type theory is presented. It extends
               Backhouse's `Do-It-Yourself Type Theory' to include inductive
               definitions of families of sets and definitions of functions by
               recursion on the way elements of such sets are generated. The
               formulation is in natural deduction and is intended to be a
               natural generalisation to type theory of Martin-L{\"o}f's theory
               of iterated inductive definitions in predicate logic. Formal
               criteria are given for correct formation and introduction rules
               of a new set former capturing definition by strictly positive,
               iterated, generalised induction. Moreover, there is an inversion
               principle for deriving elimination and equality rules from the
               formation and introduction rules. Finally, there is an
               alternative schematic presentation of definition by recursion.
               The resulting theory is a flexible and powerful language for
               programming and constructive mathematics. We hint at the wealth
               of possible applications by showing several basic examples:
               predicate logic, generalised induction, and a formalisation of
               the untyped lambda calculus.},
  journal   = {Form. Asp. Comput.},
  publisher = {Association for Computing Machinery},
  volume    = 6,
  number    = 4,
  pages     = {440--465},
  month     = jan,
  year      = 1994
}


@article{Dagand2017-nj,
  title     = {The essence of ornaments},
  author    = {Dagand, Pierre-Evariste},
  abstract  = {The essence of ornaments - Volume 27},
  journal   = {J. Funct. Programming},
  publisher = {Cambridge University Press},
  volume    = 27,
  pages     = {e9},
  month     = jan,
  year      = 2017,
  url       = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4D2DF6F4FE23599C8C1FEA6C921A3748/S0956796816000356a.pdf/div-class-title-the-essence-of-ornaments-div.pdf}
}


@article{Cockx2018-fk,
  title     = {Elaborating dependent (co)pattern matching},
  author    = {Cockx, Jesper and Abel, Andreas},
  abstract  = {In a dependently typed language, we can guarantee correctness of
               our programs by providing formal proofs. To check them, the
               typechecker elaborates these programs and proofs into a low
               level core language. However, this core language is by nature
               hard to understand by mere humans, so how can we know we proved
               the right thing? This question occurs in particular for
               dependent copattern matching, a powerful language construct for
               writing programs and proofs by dependent case analysis and mixed
               induction/coinduction. A definition by copattern matching
               consists of a list of clauses that are elaborated to a case
               tree, which can be further translated to primitive eliminators.
               In previous work this second step has received a lot of
               attention, but the first step has been mostly ignored so far. We
               present an algorithm elaborating definitions by dependent
               copattern matching to a core language with inductive datatypes,
               coinductive record types, an identity type, and constants
               defined by well-typed case trees. To ensure correctness, we
               prove that elaboration preserves the first-match semantics of
               the user clauses. Based on this theoretical work, we reimplement
               the algorithm used by Agda to check left-hand sides of
               definitions by pattern matching. The new implementation is at
               the same time more general and less complex, and fixes a number
               of bugs and usability issues with the old version. Thus we take
               another step towards the formally verified implementation of a
               practical dependently typed language.},
  journal   = {Proc. ACM Program. Lang.},
  publisher = {Association for Computing Machinery},
  volume    = 2,
  number    = {ICFP},
  pages     = {1--30},
  month     = jul,
  year      = 2018,
  url       = {https://doi.org/10.1145/3236770},
  address   = {New York, NY, USA},
  keywords  = {Agda, Copatterns, Dependent pattern matching, Dependent types}
}

@INPROCEEDINGS{Wadler1987-zp,
  title     = "Views: a way for pattern matching to cohabit with data
               abstraction",
  author    = "Wadler, P",
  booktitle = "Proceedings of the 14th ACM SIGACT-SIGPLAN symposium on
               Principles of programming languages",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "307--313",
  abstract  = "Pattern matching and data abstraction are important concepts in
               designing programs, but they do not fit well together. Pattern
               matching depends on making public a free data type
               representation, while data abstraction depends on hiding the
               representation. This paper proposes the views mechanism as a
               means of reconciling this conflict. A view allows any type to be
               viewed as a free data type, thus combining the clarity of pattern
               matching with the efficiency of data abstraction.",
  series    = "POPL '87",
  month     =  oct,
  year      =  1987,
  url       = "https://doi.org/10.1145/41625.41653"
}

@ARTICLE{Mcbride2004-fd,
  title     = "The view from the left",
  author    = "Mcbride, Conor and Mckinna, James",
  journal   = "J. Funct. Programming",
  publisher = "Cambridge University Press",
  volume    =  14,
  number    =  1,
  pages     = "69--111",
  abstract  = "The view from the left - Volume 14 Issue 1",
  month     =  jan,
  year      =  2004,
  url       = "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F8A44CAC27CCA178AF69DD84BC585A2D/S0956796803004829a.pdf/div-class-title-the-view-from-the-left-div.pdf"
}

@ARTICLE{Wadler1990-yo,
  title    = "Deforestation: transforming programs to eliminate trees",
  author   = "Wadler, Philip",
  journal  = "Theor. Comput. Sci.",
  volume   =  73,
  number   =  2,
  pages    = "231--248",
  abstract = "An algorithm that transforms programs to eliminate intermediate
              trees is presented. The algorithm applies to any term containing
              only functions with definitions in a given syntactic form, and is
              suitable for incorporation in an optimizing compiler.",
  month    =  jun,
  year     =  1990,
  url      = "https://www.sciencedirect.com/science/article/pii/030439759090147A"
}

@INCOLLECTION{McBride2006-tz,
  title     = "A Few Constructions on Constructors",
  author    = "McBride, Conor and Goguen, Healfdene and McKinna, James",
  booktitle = "Lecture Notes in Computer Science",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "186--200",
  series    = "Lecture notes in computer science",
  year      =  2006,
  url       = "http://www.e-pig.org/downloads/concon.pdf"
}
@ARTICLE{Cockx2018-bv,
  title     = "Proof-relevant unification: Dependent pattern matching with only
               the axioms of your type theory",
  author    = "Cockx, Jesper and Devriese, Dominique",
  journal   = "J. Funct. Prog.",
  publisher = "Cambridge University Press (CUP)",
  volume    =  28,
  number    = "e12",
  pages     = "e12",
  abstract  = "AbstractDependently typed languages such as Agda, Coq, and Idris
               use a syntactic first-order unification algorithm to check
               definitions by dependent pattern matching. However, standard
               unification algorithms implicitly rely on principles such
               asuniqueness of identity proofsandinjectivity of type
               constructors. These principles are inadmissible in many type
               theories, particularly in the new and promising branch known as
               homotopy type theory. As a result, programs and proofs in these
               new theories cannot make use of dependent pattern matching or
               other techniques relying on unification, and are as a result much
               harder to write, modify, and understand. This paper proposes a
               proof-relevant framework for reasoning formally about unification
               in a dependently typed setting. In this framework, unification
               rules compute not just a unifier but also a corresponding
               soundness proof in the form of anequivalencebetween two sets of
               equations. By rephrasing the standard unification rules in a
               proof-relevant manner, they are guaranteed to preserve soundness
               of the theory. In addition, it enables us to safely add new rules
               that can exploit the dependencies between the types of equations,
               such as rules for eta-equality of record types and higher
               dimensional unification rules for solving equations between
               equality proofs. Using our framework, we implemented a complete
               overhaul of the unification algorithm used by Agda. As a result,
               we were able to replace previousad-hocrestrictions with formally
               verified unification rules, fixing a substantial number of bugs
               in the process. In the future, we may also want to integrate new
               principles with pattern matching, for example, the higher
               inductive types introduced by homotopy type theory. Our framework
               also provides a solid basis for such extensions to be built on.",
  month     =  jan,
  year      =  2018,
  url       = "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E54D56DC3F5D5361CCDECA824030C38E/S095679681800014Xa.pdf/div-class-title-proof-relevant-unification-dependent-pattern-matching-with-only-the-axioms-of-your-type-theory-div.pdf",
  language  = "en"
}


@INCOLLECTION{Goguen2006-sy,
  title     = "Eliminating dependent pattern matching",
  author    = "Goguen, Healfdene and McBride, Conor and McKinna, James",
  booktitle = "Algebra, Meaning, and Computation",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "521--540",
  series    = "Lecture notes in computer science",
  year      =  2006,
  url       = "https://research.google.com/pubs/archive/99.pdf"
}

@INPROCEEDINGS{Atkey2018-pj,
  title     = "Syntax and Semantics of Quantitative Type Theory",
  author    = "Atkey, Robert",
  booktitle = "Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in
               Computer Science",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  pages     = "56--65",
  abstract  = "We present Quantitative Type Theory, a Type Theory that records
               usage information for each variable in a judgement, based on a
               previous system by McBride. The usage information is used to give
               a realizability semantics using a variant of Linear Combinatory
               Algebras, refining the usual realizability semantics of Type
               Theory by accurately tracking resource behaviour. We define the
               semantics in terms of Quantitative Categories with Families, a
               novel extension of Categories with Families for modelling
               resource sensitive type theories.",
  series    = "LICS '18",
  month     =  jul,
  year      =  2018,
  url       = "https://doi.org/10.1145/3209108.3209189",
  keywords  = "Linear Logic, Type Theory"
}

@INPROCEEDINGS{Moon2021-eb,
  title     = "Graded Modal Dependent Type Theory",
  author    = "Moon, Benjamin and Eades, III, Harley and Orchard, Dominic",
  booktitle = "Programming Languages and Systems",
  publisher = "Springer International Publishing",
  pages     = "462--490",
  abstract  = "Graded type theories are an emerging paradigm for augmenting the
               reasoning power of types with parameterizable, fine-grained
               analyses of program properties. There have been many such
               theories in recent years which equip a type theory with
               quantitative dataflow tracking, usually via a semiring-like
               structure which provides analysis on variables (often called
               ‘quantitative’ or ‘coeffect’ theories). We present Graded Modal
               Dependent Type Theory (Grtt for short), which equips a dependent
               type theory with a general, parameterizable analysis of the flow
               of data, both in and between computational terms and types. In
               this theory, it is possible to study, restrict, and reason about
               data use in programs and types, enabling, for example, parametric
               quantifiers and linearity to be captured in a dependent setting.
               We propose Grtt, study its metatheory, and explore various case
               studies of its use in reasoning about programs and studying other
               type theories. We have implemented the theory and highlight the
               interesting details, including showing an application of grading
               to optimising the type checking procedure itself.",
  year      =  2021,
  url       = "http://dx.doi.org/10.1007/978-3-030-72019-3_17"
}

@ARTICLE{Abel2023-ey,
  title     = "A Graded Modal Dependent Type Theory with a Universe and Erasure,
               Formalized",
  author    = "Abel, Andreas and Danielsson, Nils Anders and Eriksson, Oskar",
  journal   = "Proc. ACM Program. Lang.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  7,
  number    = "ICFP",
  pages     = "920--954",
  abstract  = "We present a graded modal type theory, a dependent type theory
               with grades that can be used to enforce various properties of the
               code. The theory has Π-types, weak and strong Σ-types, natural
               numbers, an empty type, and a universe, and we also extend the
               theory with a unit type and graded Σ-types. The theory is
               parameterized by a modality, a kind of partially ordered
               semiring, whose elements (grades) are used to track the usage of
               variables in terms and types. Different modalities are possible.
               We focus mainly on quantitative properties, in particular
               erasure: with the erasure modality one can mark function
               arguments as erasable.The theory is fully formalized in Agda. The
               formalization, which uses a syntactic Kripke logical relation at
               its core and is based on earlier work, establishes major
               meta-theoretic properties such as subject reduction, consistency,
               normalization, and decidability of definitional equality. We also
               prove a substitution theorem for grade assignment, and
               preservation of grades under reduction. Furthermore we study an
               extraction function that translates terms to an untyped
               λ-calculus and removes erasable content, in particular function
               arguments with the “erasable” grade. For a certain class of
               modalities we prove that extraction is sound, in the sense that
               programs of natural number type have the same value before and
               after extraction. Soundness of extraction holds also for open
               programs, as long as all variables in the context are erasable,
               the context is consistent, and erased matches are not allowed for
               weak Σ-types.",
  month     =  aug,
  year      =  2023,
  url       = "https://doi.org/10.1145/3607862",
  keywords  = "linearity, dependent types, modalities, erasure, formalization,
               graded modal type theory"
}

@INPROCEEDINGS{Brady2004-ay,
  title     = "Inductive Families Need Not Store Their Indices",
  author    = "Brady, Edwin and McBride, Conor and McKinna, James",
  booktitle = "Types for Proofs and Programs",
  publisher = "Springer Berlin Heidelberg",
  pages     = "115--129",
  abstract  = "We consider the problem of efficient representation of
               dependently typed data. In particular, we consider a language TT
               based on Dybjer’s notion of inductive families [10] and reanalyse
               their general form with a view to optimising the storage
               associated with their use. We introduce an execution language,
               ExTT, which allows the commenting out of computationally
               irrelevant subterms and show how to use properties of elimination
               rules to elide constructor arguments and tags in ExTT. We further
               show how some types can be collapsed entirely at run-time.
               Several examples are given, including a representation of the
               simply typed λ-calculus for which our analysis yields an 80\%
               reduction in run-time storage requirements.",
  year      =  2004,
  url       = "http://dx.doi.org/10.1007/978-3-540-24849-1_8"
}

@ARTICLE{Diehl2018-ba,
  title     = "Generic zero-cost reuse for dependent types",
  author    = "Diehl, Larry and Firsov, Denis and Stump, Aaron",
  journal   = "Proc. ACM Program. Lang.",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  2,
  number    = "ICFP",
  pages     = "1--30",
  abstract  = "Dependently typed languages are well known for having a problem
               with code reuse. Traditional non-indexed algebraic datatypes
               (e.g. lists) appear alongside a plethora of indexed variations
               (e.g. vectors). Functions are often rewritten for both
               non-indexed and indexed versions of essentially the same
               datatype, which is a source of code duplication. We work in a
               Curry-style dependent type theory, where the same untyped term
               may be classified as both the non-indexed and indexed versions of
               a datatype. Many solutions have been proposed for the problem of
               dependently typed reuse, but we exploit Curry-style type theory
               in our solution to not only reuse data and programs, but do so at
               zero-cost (without a runtime penalty). Our work is an exercise in
               dependently typed generic programming, and internalizes the
               process of zero-cost reuse as the identity function in a
               Curry-style theory.",
  month     =  jul,
  year      =  2018,
  url       = "https://doi.org/10.1145/3236799",
  keywords  = "dependent types, reuse, generic programming"
}

@ARTICLE{Dagand2012-aw,
  title         = "A Categorical Treatment of Ornaments",
  author        = "Dagand, Pierre-Evariste and McBride, Conor",
  journal       = "arXiv [cs.PL]",
  abstract      = "Ornaments aim at taming the multiplication of special-purpose
                   datatype in dependently-typed theory. In its original form,
                   the definition of ornaments is tied to a particular universe
                   of datatypes. Being a type theoretic object, constructions on
                   ornaments are typically explained through an operational
                   narrative. This overbearing concreteness calls for an
                   abstract model of ornaments. In this paper, we give a
                   categorical model of ornaments. As a necessary first step, we
                   abstract the universe of datatypes using the theory of
                   polynomial functors. We are then able to characterize
                   ornaments as cartesian morphisms between polynomial functors.
                   We thus gain access to powerful mathematical tools that shall
                   help us understand and develop ornaments. We shall also
                   illustrate the adequacy of our model. Firstly, we rephrase
                   the standard ornamental constructions into our framework.
                   Thanks to its conciseness, this process gives us a deeper
                   understanding of the structures at play. Secondly, we develop
                   new ornamental constructions, by translating categorical
                   structures into type theoretic artifacts.",
  month         =  dec,
  year          =  2012,
  url           = "http://arxiv.org/abs/1212.3806",
  archivePrefix = "arXiv",
  primaryClass  = "cs.PL"
}


@MISC{GMP,
  title        = "The {GNU} {MP} Bignum Library",
  howpublished = "\url{https://gmplib.org/}",
  note         = "Accessed: 2024-12-8",
  language     = "en"
}

@ARTICLE{Boulier2018-zy,
  title    = "Extending type theory with syntactic models",
  author   = "Boulier, S",
  abstract = "This thesis is about the metatheory of intuitionnistic type
              theory. The considered systems are variants of Martin-Lof type
              theory of Calculus of Constructions, and we are interested in the
              coherence of those systems and in the independence of axioms with
              respect to those systems. The common theme of this thesis is the
              construction of syntactic models, which are models reusing type
              theory to interpret type theory. In a first part, we introduce
              type theory by a minimal system and several possible extensions.
              In a second part, we introduce the syntactic models given by
              program translation and give several examples. In a third part, we
              present Template-Coq, a plugin for metaprogramming in Coq. We
              demonstrate how to use it to implement directly some syntactic
              models. Last, we consider type theories with two equalities: one
              strict and one univalent. We propose a re-reading of works of
              Coquand et.al. and of Orton and Pitts on the cubical model by
              introducing degenerate fibrancy.",
  month    =  nov,
  year     =  2018,
  url      = "https://theses.hal.science/tel-02007839/document/"
}
