\section{Related work}

Using inductive types as a form of abstraction was first explored by Wadler
\cite{Wadler1987-zp} through \emph{views}. The extension to dependent types
was developed by McBride and McKinna \cite{Mcbride2004-fd}, as part of the
Epigram project. Our system differs from views in the computational content
of the abstraction; even with deforestation \cite{Wadler1990-yo} views are not
always zero-cost, but representations are.
Atkey \cite{Atkey2011-ex} shows how to generically derive inductive types which
are refinements of other inductive types. This work could be integrated in our
system to automatically generate representations for refined data types.
Zero-cost data reuse when it comes to refinements of inductive types has been
explored in the context of Church encoding in Cedille \cite{Diehl2018-ba}, but
does not extend to custom representations.

Work by Allais \cite{Allais2023-pf,Allais2023-zq} uses a combination of views,
erasure by quantitative type theory, and universes of flattened data types to
achieve performance improvements when working with serialised data in Idris 2.
Our approach differs because we have access to `native' data representations, so
we do not need to rely on encodings. Additionally, they rely on heuristic
compiler optimisations to erase their views. On the topic of memory layout
optimisation, Baudon \cite{Baudon2023-cy} develops Ribbit, a DSL for the
specification of the memory representation of algebraic data types, which can
specify techniques like struct packing and bit-stealing. To our knowledge
however, this does not provide control over the indirection introduced by
\emph{inductive} types.

Dependently typed languages with extraction features, notably Coq
\cite{coq-extraction} and Agda \cite{agda-extraction}, have some overlapping
capabilities with our approach, but they do not provide any of the correctness
guarantees. Optimisation tricks such as the Nat-hack, and its generalisation to
other types, can emulate a part of our system but are unverified and special
casing in the compiler. Since the extended abstract version of this paper, an
optimisation was merged into Idris 2 \cite{idris-pr} to erase the forgetful and
recomputation functions for reindexing list/maybe/number-like types.
There also seems to be a demand for this kind of optimisation in Agda
\cite{agda-issue}.

% We hope
% that this work will inspire similar optimisations in other dependently typed
% languages, for which there seems to be a demand.

\section{Future work}

% We could also
% formalise the relationship between inductive families in $\lambdaind$ and the
% standard formulation in terms of $W$-types \cite{Abbott2004-va}.

In the future we aim to expand the class of theories we consider, to include
quotient-induction, induction-induction and induction-recursion. Representations
for quotient-inductive types in particular could give rise to ergonomic ways of
computing with more `traditional' data structures such as hash maps or binary
search trees. We could program inductively over these structures but extract
programs without redundancy in data representation.

We could also look into automating the discovery of inductive algebras for
`known' classes of data types through metaprogramming \cite{Dagand2017-nj}. This
could reproduce optimisation techniques by modern proof assistants but as
part of a standard library, with accompanying internal correctness proofs. It
could also extend to identity function detection, by internalising the
extraction step explored in \cref{sub:irr}.

There are elements of our formalisation which should be developed further. We
did not formulate decidability of equality and normalisation for $\lambdarep$,
which is needed for typechecking. We have developed a
normalisation-by-evaluation \cite{Altenkirch2020-rm} algorithm used in the
implementation of \superfluid, but have only sketched that it has the
desired properties (although we expect it to). We are also working on a
mechanisation of the developments of this paper in Agda.

% Due to our
% formulation in terms of algebras for theories, we expect that similar results
% can be obtained for these theories as well.

% For example, if something
% looks
% like a list/number/refinement, we could automatically generate an inductive
% algebra for it if we have access to first-class datatypes

On a more theoretical note, we define contexts in $\lambdaind$ as pairs of a
global context and a local context. In the language of categories with
families (CWF) \cite{Castellan2019-qo}, our contexts are the Grothendieck
construction $\int _{\Sigma : \Glob} \mta{Loc}\ \Sigma$. However, the base
category $\mta{Glob}$ only has weakenings, which we have left implicit.
Kaposi, Kov\'acs and Altenkirch \cite{Kaposi2019-pj} showed that algebras for a
theory form a CWF, whose initial objects are the inductive algebras. Thus we
could have morphisms between global contexts when one's items can be represented
in terms of another's. Then $\R$ could become a special case of a substitution
calculus over representations.

% Constructing a CWF this way means that terms, types and local contexts
% are presheaves with representable maps over the category of signatures.

\section{Conclusion}

This paper addresses some of the inefficiencies of inductive families in
dependently typed languages by introducing custom runtime representations that
preserve logical guarantees and simplicity of the surface language while
optimising performance and usability. These representations are formalised as inductive
algebras, and come with a framework for reasoning about them: provably zero-cost
conversions between original and represented data.

The compilation process guarantees erasure of abstraction layers, translating
high-level constructs to their defined implementations. Our hope is that by
decoupling logical structure from runtime representation, ergonomic type-driven
correctness can be leveraged without sacrificing performance.
