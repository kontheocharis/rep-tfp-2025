\section{Document plan}

We probably need to have the following sections:

\begin{itemize}
  \item Introduction
  \item Preliminaries -- category theory, conventions, basic structure of the problem
  \item Categorical model of (compilation?) Maybe it should be called something else
  \item An example with the simply-typed lambda calculus and a language with explicit
        boxing
  \item Embedding the representations into the high-level language -- dependent types
  \item Related work
  \item Conclusion + future
  \item Would be nice to have an artifact: Agda formalisation?
\end{itemize}

\section{Introduction}

There is a fundamental gap between programs written for human convenience and
programs written for machine efficiency. It can be argued that a large segment
of programming language design aims to bridge this gap, by providing
abstraction techniques that allow programmers to write programs in a high-level
language, and then compile them to a low-level language that can be executed
efficiently.

However, as the source programs become increasingly abstract and high-level,
and the compilation techniques become increasinly sophisticated in order to
keep up with the larger gap, it is very difficult to predict the final
low-level code output. As such, there can be an observed performance ceiling
for programs written in high-level languages, which can only be broken by
"getting one's hands dirty" and dropping down to low-level code, where human
intuition and insight is more effective at selecting the correct algorithms and
data structures for a given task.

This is unfortunate, however, because making this transition leads to a loss of
abstraction, and thus a loss of many things including ease of readability, ease
of modification, or even correctness guarantees. It appears as if there is a
trade-off at play. But what if we could have the best of both worlds? What if
we can write programs in a high-level, expressive, abstract language with all
the fancy features under the sun, and at the same time be able to
\emph{specify} how these programs are to be represented in a lower-level sense,
but without requiring us to repeat ourselves in terms of business logic and
data?

\section{The high-level idea}

This setup of having two sites of "programming" is not a new concept. In fact,
it could be argued that this is exactly how the process of standard compilation
works. We have a high-level language, which is compiled into a low-level
language, which is then executed on a machine.

However, the process of compilation is usually not considered to be part of the
high-level program itself. Rather, it is the job of the compiler to figure out
exactly what is the optimal representation of a high-level program in the
low-level language. This is especially the case when the discrepancy between
the levels becomes great, for example in functional languages such as Haskell
or ML. In these languages, the programmer has very little control over the
eventual representation of their program in the low-level language, unless they
use specialised primitives which are meant to mirror the low-level capabilities
of the target system.

This is what we are aiming to change with this formalism. We envision a process
of compilation in which the programmer has a lot more control over the
representation of their program in the low-level language, while still keeping
a clear separation between that and the core logic of the high-level program
itself.

\subsection{Translation of logic and data}

In the present categorical presentation of this process, we want each program
to construct its own customised compilation functor $\fun C$. This functor will
be constructed by the programmer, just like the rest of the high-level logic of
the program.

One might remark that this sounds like a lot of work for the programmer.
However, we will see that the compilation functor can be constructed
automatically based on a set of core "data type representations" that are
provided by the programmer. These data type representations will be the only
thing that the programmer will have to write, and they will be reusable across
many different programs.

Furthermore, there will be a trade-off at play. The more custom parts of the
compilation functor that are written, the more control they have over the
eventual representation, but the more coupling there is between the high-level
program and the low-level representation. Crucially however, this coupling is
never present in the high-level program itself, but rather sits alongside it.

\section{Categorical model}

Let $\cat S$ and $\cat L$ be two 2-categories. Eventually we will require
additional structure to be present in these, but for now we want to consider
them as context categories for two different type theories. We will consider
2-morphisms to be rewriting rules, and 1-morphisms to be terms, in the style of
  [CITE].

We want to view $\cat S$ as the "high-level", nice category that we want to
write our programs in. On the other hand, $\cat L$ is the "low-level", ugly
category that we actually execute our programs in. It is ugly from the point of
view of the programmer, but nice from the point of view of a machine, because
it closely follows the way the machine actually executes the program.

Since we have a high-level and a low-level category, we want to have a way to
translate between them. We will do this by defining two functors:
\begin{itemize}
  \item A functor $\fun C : \cat S \funArrow \cat L $, called the \emph{compilation}
        functor. It takes a program in $\cat S$ and compiles it to a program in $\cat
          L$.
  \item A functor $\fun Q : \cat L \funArrow \cat S $, called the \emph{quoting}
        functor. it allows us to opaquely operate on program fragments from $\cat L$
        within $\cat S$.
\end{itemize}

Importantly, both of these functors are \emph{lax}, meaning that they only
respect functoriality up to 2-morphisms. In other words, compiling a high-level
program $\fun C(f \circ g)$ is not necessarily the same as compiling $\fun
  C(f)$ and then $\fun C(g)$ separately, but there is a 2-morphism $\fun C(f)
  \circ \fun C(g) \Rightarrow \fun C(f \circ g)$ implying that one evaluates to
the other.

The quoting functor $\fun Q$ is left-adjoint to the compilation functor $\fun
  C$, in the sense that compiling a quoted program yields the same program.
Commonly this adjunction is strict.

\subsection{Features of $\cat S$}

Since $\cat S$ is the site of our high-level programs, we want it to have a lot
of the things that we expect from a programming language. In particular, we
want it to be cartesian closed, and we want it to admit fixpoints of
endofunctors. Furthermore, we expect that there exists a terminal object $1 \in
  \Ob(\cat S)$.

\subsection{Features of $\cat L$}

We require much less convenience in the structure of $\cat L$, instead relying
on the functor $\fun C$ to translate human-friendly programs into
machine-friendly ones.

Commonly $\cat L$ will not be closed, but for this paper we will assume it is.
It might sometimes be a Kleisli category with respect to some monad (probably a
monad holding the state of the stack/heap/environment/etc).

We will commonly want to restrict $\cat L$ to only be monoidal in some
less-than-cartesian way, for example to model a linear logic for the tracking
and preservation of resources.

\subsection{The category $\Repr _{\cat L} ^{\cat S}$}

The data about how to translate high-level programs into low-level programs
will be stored in a category $\Repr _{\cat L} ^{\cat S}$.

Consider the following diagram:

\begin{equation}
  \begin{tikzcd}
    \cat S \arrow[r, bend right, "\sigma"] & [25pt] \Repr _{\cat L} ^{\cat S} \arrow[l, bend right, swap, "\fun {Int}"] \arrow[l, swap, "\mu \fun {Src}"] \arrow[r, "\fun {Tar}"] \arrow[d, "\fun {Src}"] & \cat L \\
    & {[\cat S, \cat S]} \arrow[ul, bend left, "\mu"] &
  \end{tikzcd}
\end{equation}

The category $\Repr _{\cat L} ^{\cat S}$ is the category of representations of
$\cat S$ in $\cat L$. There are a few key functors here:
\begin{itemize}
  \item $\fun {Src} : \Repr _{\cat L} ^{\cat S} \funArrow [\cat S, \cat S]$ is the source
        functor. It takes a representation of $\cat S$ in $\cat L$ and returns the
        original high-level inductive type as an endofunctor in $[\cat S, \cat S]$.
        Can be considered one of the bundle projections.
  \item $\fun {Tar} : \Repr _{\cat L} ^{\cat S} \funArrow \cat L$ is the target
        functor. It takes a representation of $\cat S$ in $\cat L$ and returns the
        low-level representation of the given high-level inductive type. Can be considered
        the other bundle projection.
  \item $\mu : [\cat S, \cat S] \funArrow \cat S$ is the
        functor that takes an endofunctor in $[\cat S, \cat S]$ and returns the
        least fixpoint of that endofunctor in $\cat S$.
  \item $\sigma : \cat S \funArrow \Repr _{\cat L} ^{\cat S}$ is the functor
        that takes an object in $\cat S$ and returns the representation of that
        object in $\cat L$. It is a section of $\mu \fun {Src}$.
\end{itemize}

Each object $R \in \Repr _{\cat L} ^{\cat S}$ contains the following data:
\begin{itemize}
  \item An object $\fun \mu \fun {Src} _R \in \cat S$ which is the source type.
  \item An endofunctor $\fun {Src} _R : \cat S \funArrow \cat S$ whose fixpoint is $\mu
          \fun {Src} _R$.
  \item An object $\fun {Tar} _R \in \cat L$ which is the low-level representation of
        $\mu \fun {Src} _R$.
  \item An object $\fun {Int}_R \in \cat S$ which represents an intermediate
        descriptive object that captures information about $\mu \fun {Src} _R$ during a
        translation process. In simple cases the intermediate object will be something
        like $\fun {Int}_R = \mu \fun {Src} _R + Q \fun {Tar}_R$.
  \item A morphism $$\fun {IntAlg} _R \in \cat S (\fun {Src}_R (\fun {Int}_R), \fun
          {Int}_R)$$ which calculates the structure of the intermediate descriptive
        object by a fold over the syntactical term structure of the high-level program.
        For example, this can condense sequences of constructors of the high-level
        inductive type into a single constructor of the intermediate descriptive
        object, depending on what the algebra dictates.
  \item A morphism $$\fun {IntCoAlg} _R \in \prod _{L \in \Repr _{\cat L} ^{\cat S}}
          \cat S ( \fun {Int}_L ^{\fun {Src}_R (\fun {Int}_R)}, \fun {Int}_L ^{\fun
          {Int}_R})$$ which calculates the structure of a function on the intermediate
        object, given a function on the source object. It is almost a coalgebra, if the
        bound of the product was over all of $\cat S$ rather than just the image of
        $\fun {Int}$. Syntactically, it is used to transform pattern matches on the
        high-level inductive type into pattern matches on the intermediate descriptive
        object.
  \item A morphism $$\fun {Comp} _R \in \cat S (\fun {Int}_R , Q \fun {Tar}_R)$$ that
        "compiles" the intermediate descriptive object into the low-level
        representation (quoted).
  \item A morphism $$\fun {Decomp} _R \in \cat S (Q \fun {Tar}_R, \fun {Int}_R)$$ that
        "decompiles" the low-level representation into the intermediate descriptive
        object.
\end{itemize}

Each morphism $f \in \Repr _{\cat L} ^{\cat S} (R, R')$ contains the following
data:
\begin{itemize}
  \item TODO: Basically a morphism of each of the above data
\end{itemize}

From all this data, we should be able to construct the following functions
(morphisms in $\Set$):

\begin{itemize}
  \item A function $$\fun {int} _{\sigma, \Gamma, T} : \cat S (\Gamma, T) \to \cat S (Q
          \fun {Tar}_{\sigma \Gamma}, \fun {Int} _{\sigma T})$$ which applies all the
        $\fun {IntAlg}$ and $\fun {IntCoAlg}$ morphisms by folding and unfolding over
        the syntactical term structure of the high-level program.
  \item A function $$\fun {comp} _{\sigma, \Gamma, T} : \cat S (Q \fun {Tar}_{\sigma
            \Gamma}, \fun {Int} _{\sigma T}) \to \cat S (Q \fun {Tar}_{\sigma \Gamma}, Q
          \fun {Tar}_{\sigma T})$$ which applies the $\fun {Comp}$ morphism to the
        intermediate descriptive object.
  \item A function $$\fun {un}Q _{\sigma, \Gamma, T} : \cat S (Q \fun {Tar}_{\sigma
            \Gamma}, Q \fun {Tar}_{\sigma T}) \to \cat L (\fun {Tar}_{\sigma \Gamma}, \fun
          {Tar} _{\sigma T})$$ which essentially unquotes the result, yielding a term in
        the low-level language.
\end{itemize}

Finally, for a given section $\sigma$ of the bundle of representations, we
should be able to define the functor $\fun C$ as follows:
\begin{align*}
  \fun C_\sigma     & : \cat S \funArrow \cat L                                                                                           \\
  \fun C_\sigma (T) & := \fun {Tar} _{\sigma T}                                                                                           \\
  \fun C_\sigma (f) & := \fun {un}Q _{\sigma, \Gamma, T} \circ \fun {comp} _{\sigma, \Gamma, T} \circ \fun {int} _{\sigma, \Gamma, T} (f)
\end{align*}

NOTICE: We have not at all defined what the internal language of $\cat S$ or
$\cat L$ looks like. An advantage of this formalism is that the compilation
process in terms of algebras and coalgebras can be defined independently of the
actual syntax and semantics of the languages (modulo some requirements such as
cartesian closedness for $\cat S$).

% Consider that we have an endofunctor $\fun F : \cat S \funArrow \cat S$ which
% admits a least fixpoint, which we will denote $\mu \fun F$. This is a certain
% kind of free structure in $\cat S$: an inductive data type. We will mostly
% focus on least fixpoints, however it might be worth considering the dual case
% of greatest fixpoints as well.

% We want to be able to represent this in $\cat L$. We will do this by defining
% an algebra and a coalgebra in $\cat S$ over a chosen object $I_{\fun F} \in
%   \Ob(\cat S)$,
% \begin{equation}
%   \begin{tikzcd}
%     F(I_{\fun F}) \arrow[r, "w", shift left] & I_{\fun F} \arrow[l, "u", shift left]
%   \end{tikzcd}.
% \end{equation}
% This pair of morphisms allows us to "peel away" a layer of $\fun F$ from $I_{\fun F}$, as
% well as "wrap" a layer of $\fun F$ around $I_{\fun F}$. Conceptually, $I_{\fun F}$ represents an
% intermediary descriptive object which is used to gather and encode data about
% the structure of an inhabitant of $\mu F$.

% Furthermore, $I_{\fun F}$ must satisfy a second property: there must exist
% another pair of morphisms
% \begin{equation}
%   \begin{tikzcd}
%     I_{\fun F} \arrow[r, "r", shift left] & \fun Q(R_{\fun F}) \arrow[l, "i", shift left]
%   \end{tikzcd}.
% \end{equation}
% with the quoted object $\fun Q(R_{\fun F})$, making it so that $R_{\fun F} \in \Ob(\cat L)$ is the chosen low-level
% representation of $\mu \fun F$.

% In general we do not expect that $r$ and $i$, or $w$ and $u$ are strict
% inverses. In fact, them being strict inverses would imply a very trivial
% correspondence that probably does not contain significant information. However,
% we do expect that there exist two pairs of 2-morphisms
% \begin{equation}
%   \nu : u \circ w \Rightarrow \mathrm{id}_{\fun F(I_{\fun F})} \text{ and } \nu' : w \circ u \Rightarrow \mathrm{id}_{I_{\fun F}}
% \end{equation}
% and
% \begin{equation}
%   \mu : i \circ r \Rightarrow \mathrm{id}_{I_{\fun F}} \text{ and } \mu' : r \circ i \Rightarrow \mathrm{id}_{\fun Q(R_{\fun F})} \,.
% \end{equation}
% TODO: do we really need both directions here?
% These 2-morphisms are the key to the correspondence between the high-level and
% low-level representations. They ensure that no matter how different the composition of the
% encoding and decoding morphisms is from "doing nothing", the result always evaluates to the same term.

% For example, consider $F(X) = 1 + AX$ for some $A \in \Ob(\S)$. Then we can
% define $I_F = $, with

\subsection{Properties of the compilation functor}

The compilation functor should be coherent with respect to operational
reduction in both languages.

We can draw the following lax-commutative square:
\begin{equation}
  \begin{tikzcd}
    \cat S \arrow[r, "\mathrm{eval}"] \arrow[d, "\fun C"] & \cat S \arrow[d, "\fun C"] \\
    \cat L \arrow[r, "\mathrm{run}"]  \arrow[Rightarrow,ur]                   & \cat L
  \end{tikzcd}
\end{equation}

\section{An example of $\cat S$ and $\cat L$}

We will define and work in the internal languages of $\cat S$ and $\cat L$. By
internal language we mean that the objects of each category are the types, and
the morphisms are the terms within a given context.

For example, a morphism in $\cat S$ $$ f \in \cat S (\Gamma, A) $$ will
correspond to a term inside a context in the internal language of $\cat S$, $$
  \Gamma \vdash f : A $$.

\subsection{Definition of $\cat S$}

\begin{align*}
  x,y  \tag{variables}                                                                                                                               \\
  l,m  \tag{labels}                                                                                                                                  \\
  A, B    & ::=  A \to B \mid A \times B \mid A + B \mid \mu x . A \mid 1 \mid (l, A) \mid \int{Q} C \tag{types}                                     \\
  t, u, v & ::= \lambda x . t \mid x \mid t\,u \mid (t, u) \mid \int{p}_1(t) \mid \int{p}_2(t) \mid \int{inl}(t) \mid \int{inr}(t)                   \\
          & \mid \int{case}(t, x.u, y.v) \mid \int{q}(t) \mid \int{let}(t, u, x.v) \mid \int{letrec}(t, y.u, x.v) \mid (l, t) \mid \star \tag{terms}
\end{align*}

Why this language?

\begin{itemize}
  \item We want to be able to express inductive data types $\mu x . A$, for lists,
        numbers, trees, etc.
  \item We also want to be able to handle quoted terms of the lower language: $\int{Q}
          C$/$\int{q}(t)$, so that we can define translation functions in the language.
  \item We want to be able to explicitly label certain types and their inhabitants $(l,
          A)$/$(l, t)$, even though they might be functionally identical to some others.
        This is so that we can consider them as different objects in the category, and
        thus have the compilation functor produce different results for each one of
        them.
  \item We want to be able to express the usual constructs of a functional language:
        functions, pairs, sums, recursion, etc.
\end{itemize}

Still to do: typing rules, operational semantics.

Still to do: need an extra calculus of representations so that we can define
the extra data from $\Repr _{\cat L} ^{\cat S}$ i.e. algebras and coalgebras.

\subsection{Definition of $\cat L$}

\begin{align*}
  x,y  \tag{variables}                                                                                                         \\
  n \tag{finite natural numbers, word size}                                                                                    \\
  s    & ::= \varnothing \mid [s, t] \tag{sequences}                                                                           \\
  S    & ::= \varnothing \mid [S, C] \tag{type sequences}                                                                      \\
  C, D & ::= C \multimap D \mid \Sigma x _{n} . C \mid \int{W} \mid S[n] \mid C ^n \mid \square C \mid \int{I} \tag{types}     \\
  t, u & ::= \lambda x . t \mid x \mid t\,u \mid \langle n, t \rangle \mid \int{letpair}(t, u, x.y.v) \mid n \mid \int{box}(t) \\
       & \mid \int{letbox}(t, u, x.v) \mid s \mid \int{letseq}(t, u, x.v) \mid \int{num}(t) \mid \star \tag{terms}
\end{align*}

Why this language?

\begin{itemize}
  \item Once again we want a language based on the lambda calculus---for now we will
        not go too low-level.
  \item We want this language to be able to represent boxed types, because we want to
        have lower-level control over the memory representation of inductive data types
        (usually in the form $(l, \mu x . A)$).
  \item We allow a restricted form of dependent types in the form of $\Sigma x_n . C$
        types parameterised over some word size $\int W$. This is because sequence
        types $C^n$ are indexed by $W$, and if we have some sequence that is of some
        runtime size, we want to be able to represent the fact that some stored size is
        the size of that sequence.
  \item We want to be able to represent sequences $C^n$ for the reason above. We can
        also have sequence types which can be used to model disjoint unions (same as
        unions in C). The only difference here is we can represent tagged unions by
        using the $\Sigma$ type: $\Sigma x_2 . [A, B][x]$ is kind of like $A + B$ in
        the high-level language.
  \item Due to the presence of boxed types, we want the language to be linear. In other
        words we do not allow weakening or contraction of the context (unclear if we
        want to allow contraction or not---we do not have explicit destructors so maybe
        we really want an affine system).
  \item We don't care about labels here since that is only a concern during
        compilation.
  \item We have different let expressions for the different linear types, to be able to
        extract their inner data all at once or not at all.
  \item The category $\cat L$ is still a monoidal closed category (specifically a
        symmetric monoidal closed category), so we still allow lambdas to capture
        variables (i.e. closures). Compiling these to boxed closures is a different
        matter..
\end{itemize}

Still to do: typing rules, operational semantics.

\section{An example: Lists, numbers}

\begin{align}
  \usr{List}(A)  & := \mu X . (A \times X + 1) \tag{lists} \\
  \usr{Array}(A) & := \Sigma n . \square A ^n \tag{arrays}
\end{align}

\begin{align}
  \usr{Nat}     & := \mu X . (1 + X) \tag{numbers}                             \\
  \usr{BigUInt} & := \Sigma n . \square \int{W} ^n \tag{big unsigned integers}
\end{align}

Fully write out the representations of these types in $\cat S$ and $\cat L$.

Find less trivial examples.

% The category $\Repr ^{\cat S} _{\cat L}$ is defined as follows:
% \begin{itemize}
%   \item Objects are 7-tuples $(F, R, I, w, u, r, i)$ (TODO: write as a diagram).
%   \item Morphisms are morphisms in $\cat S \times \cat L$ of the form $(F, R) \to (F',
%           R')$.
% \end{itemize}

% Given some category $M$, we consider a functor $F : M \to [\cat S, \cat S]$
% representing a $M$-indexed family of least-fixpoint objects in $\cat S$, of the
% form $\mu X . F_m$ for each $m \in M$ (and what are the morphisms looking
% like?).

% For each of the $F_m$, we expect a corresponding object in the category $\Repr
%   ^{\cat S} _{\cat L}$, denoted by $\hat{F}_m$. In other words, we expect a
% functor $\hat{F} : M \funArrow \Repr ^{\cat S} _{\cat L}$ such that $F(m)$ is
% the first element of the 7-tuple $\hat{F}(m)$.

% Given that we have some $\mu X . A \in \cat S$ such that there exists a $a \in
%   M$ for which $\pi_F (\hat{F}(a)) = A$, then we define $C(\mu X . A) = \pi_R
%   (\hat{F}(a))$.

\section{Compilation at the same level with dependent types}

We should be able to embed the data of $\Repr ^{\cat S} _{\cat L}$ inside $\cat
  S$ if the latter has sufficient quantification structure. In other words, its
internal language is some kind of dependent type theory.

\section{Related work}

TODO: BibLatex

Bit Stealing Made Legal: \url{https://dl.acm.org/doi/pdf/10.1145/3607858}

Type fusion: \url{https://www.cs.ox.ac.uk/ralf.hinze/publications/AMAST10.pdf}

Unrolling lists: \url{https://dl.acm.org/doi/10.1145/182409.182453}

An automatic object inlining optimization and its evaluation:
\url{https://dl.acm.org/doi/10.1145/349299.349344}

Selection of representations for data structures:
\url{https://dl.acm.org/doi/pdf/10.1145/872736.806944}

Linear/non-Linear Types For Embedded Domain-Specific Languages:
\url{https://core.ac.uk/download/pdf/214213829.pdf}

Staged compilation with two-level type theory:
\url{http://arxiv.org/abs/2209.09729}

\section{Ideas about future work}

\begin{itemize}
  \item Algebra-coalgebra pairs as a way to interpret inductive data types and their
        recursive control-flow in low-level categories. (this work)
  \item Coherence conditions on an algebra-coalgebra pair to ensure that a chosen
        representation is faithful. (this work ?)
  \item Custom shortcuts for derived transformations based on the algebra-coalgebra
        pairs, for fine-tuning the representation of compound operations.
  \item Algebra-coalgebra pair generators for equivalence classes of isomorphic data
        types, to automatically generate representations of commonly seen structures.
  \item Solving for the representation that optimises some metric of a chosen set of
        operations (e.g. space complexity, time complexity, constant factors etc.)
        through various static and dynamic techniques
  \item Restriction of the context category of the source language in terms of its
        monoidal structure, to prevent certain low-level operations from being
        expressible at all.
  \item Relaxing well-foundedness, to model more complicated control-flow structures
        such as coroutines, continuations, and so on.
\end{itemize}
