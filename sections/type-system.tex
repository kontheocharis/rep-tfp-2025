\section{A type system for data representations}\label{sec:type-system}

In this section, we will develop an extension of dependent type theory with
inductive families and custom data representations. We start in
\cref{sub:algebras} by exploring the semantics of data representations in terms
of algebras for signatures. In \cref{sub:lambdaind} we define a core language
with inductive families $\lambdaind$ with data representations. The base type
theory is intensional Martin-L\"of type theory (MLTT) \cite{Martin-Lof1984-pz}
with a single universe $\univ : \univ$. We omit considerations of consistency
and universe hierarchy, though these can be added if needed. All of the examples
in the paper so far are written in a surface language that elaborates to
$\lambdaind$. In \cref{sub:lambdarep}, we define a modality $\MRepr$ that allows us
to convert between inductive types and their representations. We also define a
translation from $\lambdaind$ to \emph{extensional} MLTT, which `elaborates
away' all inductive families to their representations.

% We work in an extensional metatheory with a small universe $\Set$, $(a : A)
% \times B$ for dependent pairs, $(a : A) \to B$ for dependent products, and $=$
% for equality, and an Agda-like syntax.
Syntaxes for languages are defined in an intrinsically well-formed manner
quotiented by definitional equality \cite{Altenkirch2016-zc}, and with de-Bruijn
indices for variables. Weakening of terms is generally left implicit to reduce
syntactic noise, and often named notation is used when de-Brujin indices are
implied. We use $(a : A) \to B$ for dependent functions, $(a : A) \times B$ for
dependent pairs, $a \equiv_A a'$ for propositional equality, and $a = a' : A$
for definitional equality. Substitution is denoted with square brackets: if
$\Gamma, A \vdash B$ and $\Gamma \vdash a : A$ then $\Gamma \vdash B[a]$. We
also notationally identify elements of the universe $A : \univ$ with types $A
\type$, though explicit coercions $\mta{El}$ and $\mta{code}$ between them are
implied.
Besides the
usual judgement forms of MLTT, we also have telescopic judgement forms:
\begin{definitions}
$\Gamma \vdash \Delta \tel$                & $\Delta$ is a telescope in $\Gamma$. \\
$\Gamma \vdash \delta :: \Delta$           & $\delta$ is a spine (list of terms) matching telescope $\Delta$. \\
$\Gamma \vdash \Delta = \Delta'$           & $\Delta$ and $\Delta'$ are equal telescopes in $\Gamma$. \\
$\Gamma \vdash \delta = \delta' :: \Delta$ & $\delta$ and $\delta'$ are equal spines matching telescope $\Delta$.
\end{definitions}

Below are the formation rules for telescopes and term lists.
Since everything is intrinsically well-formed, all required pre-conditions are
implied for every inference rule.

\begin{figure}[H]
  \begin{mathpar}
  \inferrule[Tel-Empty]{ }{\Gamma \vdash \bullet \tel}
  \and
  \inferrule[Tel-Extend]{\Gamma \vdash \Delta \tel \\ \Gamma, \Delta \vdash A \type}{\Gamma \vdash (\Delta, A) \tel}
  \\
  \inferrule[Spine-Empty]{ }{\Gamma \vdash (\,) :: \bullet} \and
  \inferrule[Spine-Extend]{\Gamma \vdash \delta :: \Delta \\ \Gamma \vdash a : A[\delta]}{\Gamma \vdash (\delta, a) :: (\Delta, A)}
  \end{mathpar}
  \caption{Rules for forming telescopes and spines. Extending contexts by
  telescopes (such as $\Gamma, \Delta$) is defined mutually with these rules.}
\end{figure}

We write $\Delta \to X$ for an iterated function type with codomain $\Gamma, \Delta \vdash X$,
and $(\delta :: \Delta) \to X[\delta]$ when names are highlighted.
We will often use the notation $\delta.y$ to extract a certain index $y$ from a
spine $\delta$. This is used when we define telescopes using named notation. For
example, if $\delta :: (\textit{X} : A \to \univ, \textit{y} : (a : A) \to X\
a)$, then $\delta.X : A \to \univ$ and $\delta.y : (a : A) \to \delta.X\ a$.


\newcommand{\ValidCase}{\mta{ValidCase}}

\subsection{Algebraic signatures}

A representation of a data type must be able to emulate the behaviour of the
original data type. In turn, the behaviour of the original data type is
determined by its elimination, or induction principle. This means that a
representation of a data type should provide an implementation of induction of
the same `shape' as the original. Induction can be characterised in terms of
algebras and displayed algebras of algebraic signatures.

Algebraic signatures \cite{Adamek2010-ls,Kovacs2023-gq} consist of a list of operations, each with a specified
arity. There are many flavours of algebraic signatures with varying degrees of
expressiveness. For this paper, we are interested in algebraic signatures which can
be used as a syntax for defining inductive families in a type theory. Thus, we define
two new judgement forms:
\begin{definitions}
$\Gamma \vdash S \sig \Delta$    & $S$ is a signature with indices $\Delta$ in context $\Gamma$ \\
$\Gamma \vdash O \op \Delta$     & $O$ is an operation with indices $\Delta$ in context $\Gamma$
\end{definitions}

Signatures are lists of operations, and operations build up constructor types.

\begin{figure}[H]
  \begin{mathpar}
  \inferrule[Sig-Empty]{\Gamma \vdash \Delta \tel}{\Gamma \vdash \epsilon \sig \Delta}
  \and
  \inferrule[Sig-Extend]{\Gamma \vdash \Delta \tel \\ \Gamma \vdash O \op \Delta}{\Gamma \vdash (S \rhd O) \sig \Delta}
  \\
  \inferrule[Op-Ext]{\Gamma \vdash A \type \\ \Gamma, A \vdash O \op \Delta}
  {\Gamma \vdash (A\ \to\external O) \op \Delta} \and
  \inferrule[Op-Int]{\Gamma \vdash \delta :: \Delta \\ \Gamma \vdash O \op \Delta}
  {\Gamma \vdash (\iota\ \delta \to\internal O) \op \Delta} \and
  \inferrule[Op-Ret]{\Gamma \vdash \delta :: \Delta}
  {\Gamma \vdash (\iota\ \delta) \op \Delta}
  \end{mathpar}
  \caption{Rules for forming signatures and operations.}
\end{figure}

Each signature is described by an associated telescope of indices $\Delta$, and a
\emph{finite list} of operations:
\begin{itemize}
    \item $A \to\external O$, a (dependent) abstraction over some type $A$ from the
      type theory, of another operation $O$.
    \item $\iota\ \delta \to\internal \ O$, an
      abstraction over a recursive occurence of
      the object being defined, with indices $\delta$, of another operation
      $O$.
    \item $\iota\ \delta$, a constructor of the object being defined, with indices $\delta$.
\end{itemize}

\begin{example}[Natural numbers]\label{ex:nat-sig}
The signature for natural numbers is indexed by the empty telescope $\bullet$. It is defined as
$\Gamma \vdash (\epsilon \rhd \iota\ (\,) \rhd \iota\ (\,) \to\internal \iota\ (\,)) \sig \bullet$.
We can add labels to aid readability, and omit index spines if they are empty:
\[
\Gamma \vdash (\epsilon \rhd \textit{zero} : \iota \rhd \textit{succ} : \iota\ \to\internal \iota) \sig \bullet \,.
\]
\end{example}

\begin{example}[Vectors]\label{ex:vec-sig}
The signature for vectors of elements of type $T$ and length $n$ is indexed by the telescope $(T : \univ, n : \mathbb{N})$,
defined as
\begin{align*}
\Gamma \vdash (\epsilon &\rhd \n{nil} : (T : \univ) \to\external \iota\ T\ \n{zero} \\
&\rhd \n{cons} : (T : \univ) \to\external (n' : \mathbb{N}) \to\external (t : T) \to\external \iota\ T\ n' \to\internal \iota\ T\ (\n{succ}\ n')) \\
&\sig (T : \univ, n : \mathbb{N}) \,.
\end{align*}
Later we will see how we can use the signature in \cref{ex:nat-sig} to define the type of natural numbers $\Gamma \vdash \mathbb{N} \type$.
\end{example}

Notice that this syntax only allows occurrences of $\iota$ in positive
positions, which is a requirement for inductive types.
Different classes of algebraic signatures, theories and quantification are explored in detail by
Kov\'acs \cite{Kovacs2023-gq}.
We make no distinction between parameters and indices, though it is possible to add parameters by
augmenting the syntax for signatures with an extra telescope that must be uniform across operations.

\subsection{Interpreting signatures in the type theory} \label{sub:algebras}

In order to make use of our definition for algebraic signatures, we would like to be able to
interpret their structure as types in the type theory.

\subsubsection{Algebras}
An \emph{algebra} for a signature
$\Gamma \vdash S \sig \Delta$ and carrier type $\Gamma, \Delta \vdash X \type$
interprets the structure of $S$ in terms of the type $X$. Concretely,
this produces a telescope which matches the structure of $S$ but replaces each
occurrence of $\iota\ \delta$ with $X[\delta]$. The function arrows $\to\internal$ and
$\to\external$ in $S$ are interpreted as the function arrow $\to$
of the type theory.

\begin{example}[Natural numbers]\label{ex:nat-alg}
An algebra for the signature of natural numbers (\cref{ex:nat-sig}) over a carrier $\Gamma \vdash N \type$ is a spine matching
the telescope \[\Gamma \vdash (\n{zero}: N,\ \n{succ}: N \to N) \tel.\]
\end{example}

\begin{example}[Vectors]\label{ex:vec-alg}
An algebra for the signature of vectors (\cref{ex:vec-alg}) over a carrier $\Gamma, T : \univ, n : \mathbb{N} \vdash V \type$ is a spine matching
the telescope
\begin{align*}
 \Gamma \vdash (&\n{nil} : (T : \univ) \to V[T, \n{zero}], \\
&\n{cons} : (T : \univ) \to (n' : \mathbb{N}) \to (t : T) \to (ts : V[T,n']) \to V[T, \n{succ}\ n']) \tel.
\end{align*}
\end{example}

\subsubsection{Induction} The actual type of natural numbers $\Gamma \vdash \mathbb{N} \type$
is just the carrier of an algebra over the signature of natural numbers. In particular,
the `best' such algebra: one whose operations do not forget any information.
In the language of category theory, this is the initial algebra in the
category of algebras over the signature of natural numbers. An equivalent
formulation of initial algebras is algebras which support \emph{induction}, which is
more suitable for our (syntactic) purposes.
An algebra $\alpha :: (\textit{zero}: X,\ \textit{succ}: X \to X)$ for natural numbers supports induction if:

\begin{quote}
For any type family $X \vdash Y \type$,
if we can construct a $\textit{zero}_Y : Y[\alpha.\textit{zero}]$ and a $\textit{succ}_Y : (x : X) \to Y[x] \to Y[\alpha.\textit{succ}\ x]$,
then we can construct a $\sigma[x] : Y[x]$ for all $x : X$.
\end{quote}

The type family $Y$ is commonly called the \emph{motive}, and $(\textit{zero}_Y,
\textit{succ}_Y)$ are the \emph{methods}.
The produced term family $x : X \vdash \sigma : Y[x]$ is a \emph{section} of the type family $Y$.
Induction also requires that the section acquires its values from the provided methods.
This means that
\[\sigma[\alpha.\textit{zero}] = \textit{zero}_Y \qquad \sigma [\alpha.\textit{succ}\ x] = \textit{succ}_Y\ x\ \sigma[x].\]
We call these \emph{coherence conditions}.
A section that satisfies these conditions is called a \emph{coherent section}.
These equations might or might not hold definitionally. In the former case, we have the
definitional equalities
\begin{align*}
\Gamma &\vdash \sigma[\alpha.\textit{zero}] = \textit{zero}_Y : Y[\alpha.\textit{zero}] \\
\Gamma, x : X &\vdash \sigma[\alpha.\textit{succ}\ x] = \textit{succ}_Y\ x\ \sigma[x] : Y[\alpha.\textit{succ}\ x].
\end{align*}
In the latter case, we have a spine of propositional equality witnesses
\begin{align*}
\Gamma \vdash \sigma_{\text{coh}} :: (&\n{zero}_{\text{coh}} :  \sigma[\alpha.\textit{zero}] \equiv \textit{zero}_Y, \\
&\n{succ}_{\text{coh}} : (x : X) \to \sigma[\alpha.\textit{succ}\ x] \equiv \textit{succ}_Y\ x\ \sigma[x]).
\end{align*}

\subsubsection{Displayed algebras}
Notice that the methods $(\textit{zero}_Y, \textit{succ}_Y)$ look like an
algebra for the signature of natural numbers too, but their carrier is now a
type family over another algebra carrier $X$, and the types of the operations mention both
$X$ and $Y$, using $\alpha$ to go from $\Delta$ to $X$. These are \emph{displayed algebras}. In
general, a displayed algebra for a signature $\Gamma \vdash S \sig \Delta$,
algebra $\alpha$ for $S$ over carrier $\Gamma, \Delta \vdash X \type$, and
carrier family $\Gamma, \Delta, X \vdash Y \type$, interprets the structure of
$S$ in terms of both $X$ and $Y$. This produces a telescope which matches the
structure of $S$ but replaces each recursive occurrence $\iota\ \delta$ with an
argument $x : X$ as well as an argument $y : Y[x]$. Each operation returns a $Y$ with indices
computed from $\alpha$. Again, the function arrows in $S$ are interpreted as
function types in the type theory.

\begin{example}[Vectors]\label{ex:vec-disp-alg}
A displayed algebra for an algebra $(\n{nil}, \n{cons})$ for vectors
(\cref{ex:vec-alg}) over a carrier family $\Gamma, T : \univ, n : \mathbb{N}, v
: V[T, n] \vdash W \type$ is a spine matching
the telescope
\begin{align*}
 \Gamma \vdash (&\n{nil}_W : (T : \univ) \to W[T, \n{zero}, \n{nil}\ T], \\
&\n{cons}_W : (T : \univ) \to (n' : \mathbb{N}) \to (t : T) \to (ts : V[T,n']) \\
&\qquad \to (ts_W : W[T, n', ts]) \to W[T, \n{succ}\ n', \n{cons}\ T\ n'\ t\ ts]) \tel.
\end{align*}
\end{example}

In practice, in a call-by-value setting, it is desirable for the inductive
hypotheses of a displayed algebra ($\n{ts}_W$ above) to be
\emph{lazy} values. This improves performance when the inductive hypotheses are
not needed. Lazy values of $T$ can be implemented as functions out of the unit
type: $1 \to T$. We leave this as an implementation detail.

Finally, we come to the central definition
that classifies the algebras which
support induction:
\begin{definition}
An algebra is \emph{inductive} if every displayed algebra over it has a coherent section.
\end{definition}
The elimination rule for inductive data types in programming languages is
exactly this: given any motive and methods (a displayed algebra), we get a
dependent function from the type of the scrutinee to the type of the motive (a
section). Furthermore this function satisfies some appropriate computation rules:
when we plug in a constructor, we get the result of the method corresponding to it (the coherence conditions).
Usually in programming languages, these conditions hold definitionally, as they are the primary means
of computation with data.

\subsubsection{Uniqueness of inductive algebras}

As mentioned earlier, inductive algebras are equivalent to initial algebras.
Since initial objects are unique up to isomorphism, this suggests the following result:

\begin{theorem}\label{thm:unique-inductive-algebras}
For any given signature $S$, if we can construct two inductive algebras for $S$,
over carriers $X$ and $X'$, then there exists an isomorphism of types $X \simeq X'$. Moreover,
this isomorphism extends to the category of $S$-algebras, meaning it respects the structure of $S$.
\begin{proof}
See \cref{app:algebras}.
\end{proof}
\end{theorem}


\subsection{Defining algebras and friends}

In order to utilise these constructions for our type system, we now explicitly define
the follwing objects:
\begin{definitions}
$\Gamma \vdash S\A\ X \tel$ & Algebras for a signature $\Gamma \vdash S \sig \Delta$ over a carrier $\Gamma, \Delta \vdash X \type$. \\
$\Gamma \vdash \alpha\D\ Y \tel$ & Displayed algebras for an algebra $\Gamma \vdash \alpha :: S\A\ X$ over a motive $\Gamma, \Delta, X \vdash Y \type$. \\
$\Gamma \vdash \beta\COH\ \sigma \tel$ & Propositional coherences for a section $\Gamma, \Delta, X \vdash \sigma : Y$ of a displayed algebra $\Gamma \vdash \beta :: \alpha\D\ Y$.
\end{definitions}

All constructions labelled with superscripts are not part of the syntax of the
type system, but rather functions in the metatheory which compute syntactic
objects such as telescopes.

The algebras for a signature are defined
by case analysis on $S$:
\begin{align*}
&\boxed{\Gamma \vdash S\A\ X \tel} \\
&\epsilon\A\ X = \bullet \qquad (S' \rhd O)\A\ X = ({S'}\A\ X,\ (\nu :: O\IN\ X) \to X[\nu\OUT])
\end{align*}
An empty signature $\epsilon$ produces an empty telescope, while an extended
signature $S' \rhd O$ produces a telescope extended with a function
corresponding to $O$. This function goes from the inputs of $O$ interpreted in
$X$, to $X$ evaluated at the output indices.
The inputs and outputs of each operation $O$ in an algebra are defined by case
analysis on $O$:
\begin{block}
\setlength{\tabcolsep}{10pt}
\begin{tabular}{ll}
$\boxed{\Gamma \vdash O\IN\ X \tel}$ & \boxed{\Gamma \vdash \{O\}\ \nu\OUT :: \Delta} \\[1em]
{$\begin{aligned}
&(A\to\external O')\IN\ X = (a : A,\ O'[a]\IN\ X) \\
&(\iota\ \delta \to\internal O')\IN\ X = (x : X[\delta],\ {O'}\IN\ X) \\
&(\iota\ \delta)\IN\ X = \bullet
\end{aligned}$}
&
{$\begin{aligned}
&\{O = A \to\external O'\}\ (a, \nu')\OUT = {\nu'}\OUT \\
&\{O = \iota\ \delta \to\internal O'\}\ (x,\ \nu')\OUT = {\nu'}\OUT  \\
&\{O = \iota\ \delta\}\ (\,)\OUT = \delta
\end{aligned}$}
\end{tabular}
\end{block}


% We can similarly define internal displayed algebras over external algebras $(X,
% x) : \mta{Alg}\ T$ as
% \begin{align*}
%     &\mta{dispAlgebra}\statement that is true in a model (X, x) : \Tel\ (\Gamma \rhd M : \Ty\ (\Gamma \rhd P \rhd X)) \\
%     &\mta{dispAlg}\ (X, x) := \bullet \rhd M : \Ty\ (\Gamma \rhd P \rhd X) \rhd \mta{dispAlgebra}\ (X, x)
% \end{align*}
% and finally sections as
% \begin{align*}
%     &\mta{Sec}\ M := \Tm\ (\Gamma \rhd P \rhd X)\ M \\
%     &\mta{Coh}\ f := \forall a. f[\Msub{\mta{out}\ a; x\ a}] = m\ (\mta{disp}\ f\ a) \\
%     &\mta{Section}\ (M, m) := (f : \mta{Sec}\ M) \times \mta{Coh}\ f
% \end{align*}

A similar construction can be performed for displayed algebras over algebras.
Displayed algebras are defined by case analysis on $S$, which is an implicit parameter of $-\D$.
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \alpha\D\ Y \tel} \\
& \{S = \epsilon\}\ (\,)\D\ Y = \bullet \\
&\{S = S' \rhd O\}\ (\alpha', \alpha_O)\D\ Y = ({\alpha'}\D\ Y,\ (\mu :: \alpha_O\DI\ Y) \to Y[\mu\DO])
\end{align*}
We provide the definitions of $-\DI$ and $-\DO$ in the appendix (\cref{app:algebras}), but they are similar to
the definitions of $-\IN$ and $-\OUT$.

Next we define the coherence conditions for a displayed algebra as a telescope
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \{\alpha\}\ \beta\COH\ \sigma \tel} \\
& \{S = \epsilon\}\ \{\alpha = (\,)\}\ (\,)\COH\ \sigma = \bullet \\
& \{S = S' \rhd O\}\ \{\alpha = (\alpha', \alpha_O)\}\ (\beta', \beta_O)\COH\ \sigma \\
&\qquad = ({\beta'}\COH\ \sigma,\ (\nu :: O\IN\ X) \to \sigma[\alpha_O\ \nu] \equiv \beta_O\ (\sigma \, \$ \, \nu))
\end{align*}
The notation $\sigma \, \$\, \nu$ applies the section $\sigma$ to the input $\nu$,
yielding a displayed input by sampling the section to get the inductive
hypotheses (defined in \cref{app:algebras})

Now we can define induction for an algebra $\alpha$ as a type
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \alpha\IND \type} \\
&\{S\}\ \alpha\IND = (Y : (\delta :: \Delta) \to X[\delta] \to \univ) \to (\beta :: \alpha\D\ (\delta.\ x.\ Y\ \delta\ x)) \\
&\qquad\to (\sigma : (\delta :: \Delta) \to (x : X[\delta]) \to Y\ \delta\ x)) \times \beta\COH\ (\delta.\ x.\ \sigma\ \delta\ x).
\end{align*}
where $Y$ is the motive, $\beta$ are the methods, and $\sigma$ is the output section which must
satisfy the propositional coherence conditions.
Finally, we can package an inductive algebra over a signature as a telescope
\begin{align*}
&\boxed{\Gamma \vdash S\INDA \tel} \\
&S\INDA = (X : \Delta \to \univ,\ \alpha :: S\A\ (\delta.\ X\ \delta),\ \kappa : \alpha\IND),
\end{align*}
by collecting the carrier $X$, algebra $\alpha$ and induction $\kappa$ all together.

\subsection{Constructing inductive families}\label{sub:lambdaind}

We now extend intensional MLTT with a type for inductive families, which we
denote $\Mdata_\Delta\ S\ \gamma$. This type defines an inductive family
matching a signature $S$ with indices $\Delta$, together with an inductive
algebra $\gamma$ which `implements' the signature $S$. Notice that this is
different to the usual way that inductive families are defined in type theory,
for example W-types \cite{Abbott2004-va}, where all we need to provide is
a signature.\footnote{
Notice that the data defining a W-type $(A : \univ, B : A \to \univ)$ can be viewed as a kind of signature, where $A$ describes the
operations and their non-recursive parameters, while $B$ describes the recursive parameters.}
Here, we must also implement the signature and prove
the induction principle by providing $\gamma$, rather than it being `provided' by
the type theory. For example, if our type theory W-types, then we can
implement the signature using W-types. In effect, this will later allow us to
`elaborate away' inductive definitions to their defined representations.
This leads us to the formal definition of a representation:
\begin{definition}
A \emph{representation} of a signature $S$ is an inductive algebra for $S$.
\end{definition}
In \cref{fig:data-rules} we define the $\Mdata$ type, and its corresponding
introduction, elimination, and computation rules.

\begin{figure}[H]
\begin{mathpar}
\inferrule[Data-Form]
{\Gamma \vdash S \sig \Delta \\ \Gamma \vdash \gamma :: S\INDA \\ \Gamma \vdash \delta :: \Delta}
{\Gamma \vdash \Mdata_\Delta\ S\ \gamma\ \delta \type} \and
\inferrule[Data-Intro]
{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
{\Gamma \vdash \Mctor_{S.O}\ \nu : \Mdata_\Delta\ S\ \gamma\ \nu\OUT} \and
\inferrule[Data-Elim]
{\Gamma,\ \delta :: \Delta,\ \Mdata_\Delta\ S\ \gamma\ \delta \vdash M \type \\
\Gamma \vdash \beta :: \Mctor_S\D\ M \\
\Gamma \vdash \delta :: \Delta \\
\Gamma \vdash x : \Mdata_\Delta\ S\ \gamma\ \delta}
{\Gamma \vdash \Melim_S\ M\ \beta\ \delta\ x : M[\delta, x]} \and
\inferrule[Data-Comp]
{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma) \\
\Gamma,\ \delta :: \Delta,\ \Mdata_\Delta\ S\ \gamma\ \delta \vdash M \type \\
\Gamma \vdash \beta :: \Mctor_S\D\ M}
{\Gamma \vdash \Melim_S\ M\ \beta\ \nu\OUT\ (\Mctor_{S.O}\ \nu) = \beta_O\ (\Melim_S\ M\ \beta \ \$\ \nu) : M[\nu\OUT, \Mctor_{S.O}\ \nu]}
\end{mathpar}
\caption{Rules for data types, constructors and eliminators. We write $O \in S$
to indicate that $O$ is an operation in the signature $S$. We write $\alpha_O$
to extract the telescope element corresponding to operation $O$ from the algebra
$\alpha$ for $S$.}
\label{fig:data-rules}
\end{figure}

Constructors form an algebra for the signature $S$ over
$\Mdata_\Delta\ S\ \gamma$, denoted by $\Mctor_S = (\Mctor_{S.O})_{O \in S}$.
Similarly, the eliminator forms a coherent section over the constructor algebra,
which holds definitionally.

One might think, what do we gain by adding $\Mdata$ to the theory? If we can
provide an inductive algebra $\gamma$ for a signature $S$ ourselves, then why
not just use $\gamma$ directly? The reason is that by having a primitive for
inductive types, we can take advantage of their properties in an extensional
way. For example, an induction principle suggests that the constructors
corresponding to each method are disjoint. Since constructors $\Mctor$ are a
primitive term in the theory, we can make use of this when formulating a
unification algorithm. Aside from disjointness, we can also rely on other
properties such as injectivity, acyclicity, and `no-confusion'. McBride
\cite{McBride2006-fp} originally explored the properties which arise from the
existence of induction principles, or equivalently, initiality.

For example, if we have an inductive algebra $(\n{N}, \n{zero}_{\n{N}},
\n{succ}_{\n{N}}, \n{elim}_{\n{N}})$ for the natural numbers signature
$\n{NatSig}$, we can prove propositionally that for all $x : \n{N}$,
$\n{zero}_{\n{N}} \neq \n{succ}_{\n{N}}\ x$, by invoking $\n{elim}_{\n{N}}$.
However, the typechecker does not know this fact; it is not derivable as a
definitional equality contradiction. However, it \emph{is} derivable
definitionally that for all $x : \mathbb{N}$, $\Mctor_{\n{zero}} \neq
\Mctor_{\n{succ}}\ x$, where $\mathbb{N} = \Mdata\ {\n{NatSig}}\ (\n{N},
\n{zero}_{\n{N}}, \n{succ}_{\n{N}}, \n{elim}_{\n{N}})$ because the
metatheoretic quotient-inductive syntax does not equate $\Mctor_i$ and
$\Mctor_j$ unless $i = j$.

Another way to state this is that the existence of $\Mdata$ enables the use of
\emph{dependent pattern matching} on its inhabitants. Nested pattern matching on
$\mathbb{N}$, for example, can be elaborated to invocations of
$\Melim_{\n{NatSig}}$, which has the expected computation rules as shown in
\cref{fig:data-rules}. Converting dependent pattern matching to eliminators has
been explored in depth by Goguen, McBride and McKinna \cite{Goguen2006-sy}, as
well as by Cockx and Devriese \cite{Cockx2018-bv} in absence of Axiom K. These
methods can be used to implement pattern matching on $\Mdata$.

\subsection{Reasoning about representations} \label{sub:lambdarep}

So far we are able to construct data types using the $\Mdata_\Delta\ S\ \gamma$
type constructor. These data types are themselves implemented in terms of
inductive algebras. However, the rules for data types do not utilise them. We
would like to be able to relate data types to their underlying inductive
algebras. One reason is to avoid unnecessary
computation. If we have a type $X$ that is the carrier of two inductive algebras
$(X, \alpha, \kappa)$ and $(X, \alpha', \kappa')$ for signatures $S$ and
$S'$ respectively, then we can form the data types $D = \Mdata_\Delta\ S\ (X,
\alpha, \kappa)$ and $D' = \Mdata_\Delta\ {S'}\ (X, \alpha', \kappa')$ and make
use of the structural properties of initiality. However, we would also like to
be able to freely convert between $X$, $D$ and $D'$ without incurring any
runtime cost. After all, $D$ and $D'$ are meant to be translated away to their
underlying representation, $X$. This argument can also be made in the context of
theorem proving: sometimes it is easier to prove a property about $D$ or $D'$,
due to their structure, but we should be able to `transport' the property to
$X$.

To make use of these conversions in a computationally-irrelevant manner,
while still retaining the fact that $D$, $D'$ and $X$ are distinct types,
we introduce a modality
$$
\MRepr : \univ \to \univ ,
$$
which takes types to their representations. This modality definitionally
preserves all the type formers of the theory, other than $\Mdata$. It comes with
two term formers $\Mrepr$ and $\Munrepr$, which are definitional inverses of each other.
We highlight the main rules of $\MRepr$ in \cref{fig:repr-rules}. The full definition
is given in \cref{app:algebras}.

\begin{figure}[H]
\begin{mathpar}
\inferrule[Repr-Form]{\Gamma \vdash A \type}{\Gamma \vdash \MRepr\ A \type} \and
\inferrule[Repr-Intro]{\Gamma \vdash a : A}{\Gamma \vdash \Mrepr\ a : \MRepr\ A} \and
\inferrule[Repr-Elim]{\Gamma \vdash a : \MRepr\ A}{\Gamma \vdash \Munrepr\ a : A} \and
\inferrule[Repr-Beta]{\Gamma \vdash a : \MRepr\ A}
{\Gamma \vdash \Mrepr\ (\Munrepr\ a) = a : \MRepr\ A} \and
\inferrule[Repr-Eta]{\Gamma \vdash a : A}
{\Gamma \vdash \Munrepr\ (\Mrepr\ a) = a : A} \and
\inferrule[Repr-Data]{\Gamma \vdash S \sig \Delta \\ \Gamma \vdash \gamma :: S\INDA}
{\Gamma \vdash \MRepr\ (\Mdata_\Delta\ S\ \gamma\ \delta) = \gamma.X\ \delta} \and
\end{mathpar}
\caption{Introduction and elimination forms, as well as computation rules
for the $\MRepr$ modality. It also commutes with the rest of the syntax
definitionally.}
\label{fig:repr-rules}
\end{figure}

These rules allow us to go between a data type $D = \Mdata_\Delta\ S\ \gamma\
\delta$ and its representation $\gamma.X\ \delta$. In the translation to
extensional MLTT that we are yet to define, this modality is also translated
away. The computation rules for the $\MRepr$ modality will be
justified by computation rules in extensional MLTT. Since $\Mdata$ does not
already have any associated computation rules, these rules also preserve the
decidability of conversion checking, though we do not show this here.

One might hope for additional computation rules. For example, representing a constructor
should be equal to the underlying algebra element of the constructor type's
representation:\footnote{When we write $\Mrepr\ \nu$ we
mean to apply $\Mrepr$ to all recursive occurences (all places that $\iota$ appears in the domain of $O$).}
\[\Mrepr\ (\Mctor_{S.O}\ \nu) = \gamma.\alpha_O\ (\Mrepr \  \nu) \,.\]
Unfortunately, having this as a computation rule
would render conversion checking undecidable, because if one applies
$\mta{unrepr}$ to a term $\Mrepr\ (\Mctor_{S.O}\ \nu)$ which has already been reduced
to its representation, $\mta{unrepr}\ (\gamma.\alpha_O\ (\Mrepr\ \nu))$, there is no
clear way to decide that this is convertible to $\Mctor_{S.O}\ \nu$ even though the
definitional equality rules would imply that it is (due to \textsc{Repr-Eta}).
Nevertheless, we can still postulate this equality propositionally, and it is justified
by the translation step. Similar postulates can also be made available for
eliminators, which are listed in \cref{app:reprs}.
% \begin{mathpar}
% \inferrule[Repr-Ctor]{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
% {\Gamma \vdash \mta{repr-ctor}_{S.O}\ \nu : \Mrepr\ (\Mctor_{S.O}\ \nu) \equiv \gamma.\alpha_O\ (\Mrepr \  \nu)} \and
% \inferrule[Repr-Elim]{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
% {\Gamma \vdash \mta{repr-elim}_{S}\ M\ \beta\ \delta\ x : \Melim_{S}\ M\ \beta\ \delta\ x
% \equiv (\gamma.\kappa\ (\lambda\delta.\ \lambda x.\ M[\delta, \Munrepr\ x])\ (\Mrepr^*\ \beta)).\sigma\ \delta\ (\Mrepr\ x)}
% \end{mathpar}

\subsubsection{Subuniverse of concrete types}

We can view the image of $\MRepr$ as a subuniverse of $\univ$. The restriction to
its image
$$
\MRepr : \univ \to \univ_C \,.
$$
targets a universe of types which do not contain any $\Mdata$ types.


We extend the language $\lambdaind$ to form $\lambdarep$, which allows the
definition of custom representations for data types and global functions. The
machinery of algebras that we have developed in \cref{sub:algebras} allows for a
very direct definition of representations of data types: A representation for a
$\mta{data}\ P\ T$ is an inductive algebra for $T$.
Representations live alongside items in a global context, and each item only corresponds
to at most one representation. We achieve this by adding a constructor to global contexts
$\unrhd : (\Sigma : \Glob) \to (I : \Item\ \Sigma) \to \Rep\ \Sigma\ I \to \Glob$.
Representations are defined inductively by
\begin{align*}
% & \Rep : (\Sigma : \Sig) \to \Item\ \Sigma \to \Set \\
& \mta{datarep} : \Tms\ (\Sigma, \epsilon)\ (\mta{indAlg}\ T) \to \Rep\ \Sigma\ (\mta{data}\ P\ T) \\
& \mta{defrep} : (x : \Tm\ (\Sigma, P)\ A) \to \Tm\ (\Sigma, P)\ (\mta{Id}\ x\ t) \to \Rep\ \Sigma\ (\mta{def}\ P\ A\ t)
\end{align*}
We will write $\mta{datarep}\ (R, r, Q)$ to unpack the telescope of an inductive
algebra with carrier $R$, algebra $r$ and induction
$Q$. Representations for definitions are also included, where a definition can
be represented by a term propositionally equal to original definition, but
perhaps with better computational properties.

\subsubsection{Translating to extensional MLTT}

\subsection{Reasoning about representations} \label{sub:reasoningrep}

To allow reasoning about representations internally to $\lambdarep$ we add a
type former $\MRepr{} : \Ty\ \Gamma \to \Ty\ \Gamma$
along with two new terms in the syntax, forming an isomorphism
\begin{equation}\label{eq:repr-iso}
	\Mrepr{} : \Tm\ \Gamma\ T \simeq \Tm\ \Gamma\ (\MRepr\ T) : \Munrepr{}
\end{equation}
which preserves $\Pi$/$\mta{Id}$/$\univ$. The type $\MRepr\ T$ is the
defined representation of the type $T$. The term $\Mrepr{}$ takes a term of type
$T$ to its representation of type
$\MRepr\ T$, and $\Munrepr{}$ undoes the effect of $\Mrepr{}$, treating a
represented term as an inhabitant of its original type. These new constructs
come with equality constructors in the syntax
shown in \cref{fig:lambdaind-repr-coherence-pi-univ}.
\begin{figure}[H]
  \begin{minipage}[t]{0.5\textwidth}%
  \begin{alignat*}{1}
  & \mta{reprr} : \Munrepr\ (\Mrepr\ t) \equiv t \\
  & \mta{reprl} : \Mrepr\ (\Munrepr\ t) \equiv t \\[1em]
  & \MRepr\text{-}\Pi : \MRepr\ {(\Pi\ T\ U)} \equiv \Pi\ T\ (\MRepr\ U) \\
  & \Mrepr\text{-}\lambda : \Mrepr\ {(\lambda\ u)} \equiv \lambda\ (\Mrepr\ u) \\
  & \Munrepr\text{-}\lambda : \Munrepr\ {(\lambda\ u)} \equiv \lambda\ (\Munrepr\ u) \\
  & \Mrepr\text{-}@ : \Mrepr\ (\ap f) \equiv \ap {(\Mrepr\ f)} \\
  & \Munrepr\text{-}@ : \Munrepr\ (\ap f) \equiv \ap {(\Munrepr\ f)} \\[1em]
  & \Mrepr[] : \Mrepr\ {(t[\sigma])} \equiv (\Mrepr\ {t})[\sigma] \\
  & \Munrepr[] : \Munrepr\ {(t[\sigma])} \equiv (\Munrepr\ {t})[\sigma] \\
  & \MRepr[] : \MRepr\ {(T[\sigma])} \equiv (\MRepr\ {T})[\sigma]
  \end{alignat*}
  \end{minipage}%
  \begin{minipage}[t]{0.5\textwidth}%
  \begin{alignat*}{1}
  & \MRepr\text{-}\univ : \MRepr\ {\univ} \equiv \univ \\
  & \Mrepr\text{-}\Code{} : \Mrepr\ {(\Code T)} \equiv \Code T \\
  & \Munrepr\text{-}\Code{} : \Munrepr\ {(\Code T)} \equiv \Code T \\[1em]
  & \MRepr\text{-}\mta{Id} : \MRepr\ (\mta{Id}\ a\ b) \equiv \mta{Id}\ (\Mrepr\ a)\ (\Mrepr\ b) \\
  & \Mrepr\text{-}\mta{refl} : \Mrepr\ (\mta{refl}\ u) \equiv \mta{refl}\ (\Mrepr\ u) \\
  & \Munrepr\text{-}\mta{refl} : \Munrepr\ (\mta{refl}\ u)  \equiv \mta{refl}\ (\Munrepr\ u) \\
  & \Mrepr\text{-}\mta{J} : \Mrepr\ (\mta{J}\ C\ w\ e) \\ & \qquad \qquad  \equiv \mta{J}\ (\mta{Repr}\ C)\ (\mta{repr}\ w)\ e \\
  & \Munrepr\text{-}\mta{J} : \Munrepr\ (\mta{J}\ (\mta{Repr}\ C)\ w\ e) \\ &  \qquad \qquad  \equiv \mta{J}\ C\ (\mta{unrepr}\ w)\ e
  \end{alignat*}
  \end{minipage}%
  \caption{Coherence of the representation operators with substitutions, $\Pi$, $\mta{Id}$,
  and universes . The terms $\MRepr\ (\El{t})$, $\Mrepr\ (\pi_2 \sigma)$ and
  $\Munrepr\ (\pi_2 \sigma)$ do not reduce.}
  \label{fig:lambdaind-repr-coherence-pi-univ}
\end{figure}

So far the representation operators do not really do much other than commute
with almost everything in the syntax. In order to make
them useful, we need to define how they compute when they encounter data types
which have a defined representation in the global context.
We use a decidable relation $R \in_i \Sigma'$ to mean that $R :
\mta{Rep}\ \Sigma\ I$ is the representation of an item $I : \mta{Item}\ \Sigma$
where $i : I \in \Sigma'$.
This relation is a proposition, so it is proof-irrelevant. Furthermore, it is stable under
substitutions and global weakening, because each item can only be represented once in a global context.
In the following rules, $r : \mta{datarep}\ (R, r, Q) \in_i \Sigma$.

Firstly, we define the reduction that occurs when a type $\mta{D}\ i$ is represented,
\begin{equation}
  \mta{Repr-D}_i : \forall r.\ \MRepr\ (\mta{D}\ i) = \mta{El}\ R@ \,, \label{eq:lambdaind-Repr-D}
\end{equation}
yielding the carrier $R$ of the inductive algebra that represents it (after
converting it from a function into the universe to a type family).

Next, we add a rule for representing constructors, albeit in propositional form, where
\begin{equation}
\mta{repr-C}_i : \forall r.\ \Tm\ (\Sigma, \Delta)\ (\mta{Id}\ (\Mrepr\ (\mta{C}\ a))\ (\emb{r}\ a^\mta{Repr}))  \label{eq:repr-ci}
\end{equation}
Here, the operation $\_^{\mta{Repr}}$ is used to apply the term former
$\mta{repr}$ to the recursive part of the arguments $a$. The full construction
can be found in \cref{app:reprs} of the appendix

One might be tempted to make this equality definitional too. Unfortunately, this
would render conversion checking undecidable, because if one applies
$\mta{unrepr}$ to a term $\Mrepr\ (\mta{C}\ a)$ which has already been reduced
to its representation, $\mta{unrepr}\ (\emb{r}\ a^{\mta{Repr}})$, there is no
clear way to decide that this is convertible to $\mta{C}\ a$ even though the
definitional equality rules would imply that it is (due
to the annihilation of $\mta{repr}$ and $\mta{unrepr}$). There is no
equivalent of $\mta{unrepr}$ for types, so \eqref{eq:lambdaind-Repr-D} preserves
the decidability of conversion checking.


We can also add a propositional equality rules for representing eliminators.
First, representing an eliminator just applies $\mta{repr}$ to the motive and methods:
\begin{align*}
&\mta{repr-E}_i : \forall r.\ \Tm\ (\Sigma, \Delta)\ (\mta{Id}\ (\Mrepr\ (\mta{E}\ m))\ (\mta{E}\ m^\mta{Repr})) \\
&\mta{unrepr-E}_i : \forall r.\ \Tm\ (\Sigma, \Delta)\ (\mta{Id}\ (\Munrepr\ (\mta{E}\ m))\ (\mta{E}\ m^\mta{Unrepr}))
\end{align*}
Additionally, eliminating something using $\mta{E}$ should be the same as
eliminating the representation of that thing using the represented eliminator $Q$:
\begin{align*}
&\mta{repr-equiv-E}_i : \forall r.\ \Tm\ (\Sigma, \Delta)\ (\mta{Id}\ (\mta{E}\ m)\ (s.\ (\emb{Q}_0\ m^{\mta{Repr*}})[\Msub{\mta{repr}\ s}])))
\end{align*}
Above we use more auxilliary definitions which represent the carriers of
algebras, as well as displayed algebras (appendix \cref{app:reprs}):
\begin{align*}
\_^{\mta{Repr}} &: \mta{Algebra}\ T\ X \to \mta{Algebra}\ T\ (\mta{Repr}\ X) \\
 \_^{\mta{Repr}} &: \mta{DispAlgebra}\ a\ M \to \mta{DispAlgebra}\ a\ (\MRepr\ M) \\
 \_^{\mta{Repr}*} &: \mta{DispAlgebra}\ a\ M \to \mta{DispAlgebra}\ a^{\mta{Repr}}\ (p\ x .\ M[\Msub{p;\mta{unrepr}\ x}])
\end{align*}

We do not need an additional equality rule for representing function definitions
as this is given by the equality proof $p$ in the definition of a
representation $\mta{defrepr}\ t\ p$, when accounting for the definitional
equality between a definition and its implementation.

\subsection{Translating representations away}

We now define a translation step $\R$ from $\lambdarep$ to
$\lambdaind^{\lang{ext}}$, meant to be applied during the compilation process.
More specifically, the translation target is the extensional flavour of
$\lambdaind$ by adding the equality reflection rule. General undecidability of
conversion is not a problem because type checking is decidable for
$\lambdarep$\footnote{Not formalised in this paper.} and we only need to apply this
transformation after type checking, on fully-typed terms. The translation is
defined over the syntax of $\lambdarep$ \cite{Boulier2017-cm} such that
definitional equality is preserved. Overall, $\R$ preserves the structure of
$\lambdarep$, but maps constructs to their `terminal' representations.
First, we define a translation of global contexts $\R : \Glob_\rep \to \Glob_\ind^\lang{ext}$ as
\[
\R\ \bullet := \bullet \qquad \R\ (\Sigma \rhd I) := \R \Sigma \rhd \R I \qquad \R\ (\Sigma \unrhd I \ R) := \R \Sigma
\]
which erases all items with defined representations.
This utilises a translation of items $\R : \Item_\rep\ \Sigma \to \Item_\ind^\lang{ext}\ \R
\Sigma$ which simply recurses on all subterms with $\R$.
Types are translated as
\begin{align*}
  & \R : \Ty_\rep\ (\Sigma, \Delta)\ \to \Ty_\ind^\lang{ext}\ (\R \Sigma, \R \Delta) \\
  & \R\ (\mta{D}\ i) := \begin{cases}
  \R\ (\mta{El}\ R@) & \text{if $\mta{datarep}\ (R, r, Q) \in_i \Sigma$} \\
  \mta{D}\ \R i & \text{otherwise}
  \end{cases}  \qquad \R\ (\MRepr\ T) := \R T \\
  & \text{(otherwise recurse on all subterms with $\R$)} \,.
\end{align*}
The definitional equality rules of $\mta{Repr}$ and $\mta{D}$ are mirrored, but $\R$ is now applied
to all subterms.
Similarly, terms are translated as
\begin{align*}
  & \R : \Tm_\rep\ (\Sigma, \Delta)\ T \to \Tm_\ind^\lang{ext}\ (\R \Sigma, \R \Delta)\ \R T \\[1em]
  &\R\ (\mta{C}_i\ a) = \begin{cases}
      \emb{\R r}\ \R a & \text{if}\ \mta{datarep}\ (R, r, Q) \in_i \Sigma \\
      \mta{C}_{\R i}\ \R a & \text{otherwise}
  \end{cases} \\
  &\R\ (\mta{E}_i\ m) = \begin{cases}
      \emb{\R Q}_0\ \R m & \text{if}\ \mta{datarep}\ (R, r, Q) \in_i \Sigma \\
      \mta{E}_{\R i}\ \R m & \text{otherwise}
  \end{cases} \\
  &\R\ (\mta{F}_i) = \begin{cases}
        \R t & \text{if}\ \mta{defrep}\ t\ p \in_i \Sigma \\
        \mta{F}_{\R i} & \text{otherwise}
    \end{cases}  \qquad \R\ (\Mrepr\ t) ,\ \R\ (\Munrepr\ t) := \R t \\[1em]
  & \R\ (\mta{repr-C}_i\ a),\ \R\ (\mta{repr-E}_i\ m),\ \R\ (\mta{unrepr-E}_i\ m),\ \R\ (\mta{repr-equiv-E}_i\ m) \text{ := } \mta{refl} \\[1em]
  & \text{(otherwise recurse on all subterms with $\R$)}
\end{align*}
Constructor, eliminator and definition translations mirror the equality rules in
\cref{sub:lambdarep}, but apply $\R$ to all subterms rather than only the
recursive occurrences of the data type being represented. As a result, all of
the propositional equality constructors are translated to reflexivity, since
after applying $\R$ both sides are identical.

The equality constructors of the syntax of $\lambdarep$ must also be translated.
The base equalities of the theory are preserved by their counterparts in
$\lambdaind^\lang{ext}$. The coherence rules for representation operators
(\cref{fig:lambdaind-repr-coherence-pi-univ}) are preserved by metatheoretic
reflexivity on the other side, since all representation operators are erased.
Finally, coherence rules for definitions $\mta{F}$ and eliminators $\mta{E}$ are
preserved by reflecting the propositional coherence rules provided by their
defined representations:
\begin{align*}
& \mta{ap}_\R\ (\mta{E-id}_i\ m) :=
\begin{cases}
    \mta{reflect}\ \emb{\R Q}_1\ \R m & \text{if}\ \mta{datarep}\ (R, r)\ Q \in_i \Sigma \\
    \mta{E-id}_{\R i}\ \R m & \text{otherwise}
    \end{cases} \\
    & \mta{ap}_\R\ (\mta{F-id}_i) :=
    \begin{cases}
        \mta{reflect}\ \R p & \text{if}\ \mta{defrep}\ t\ p \in_i \Sigma \\
        \mta{F-id}_{\R i} & \text{otherwise}
        \end{cases} \\
& \text{(otherwise recurse on all equality constructors with $\mta{ap}_\R$)}
\end{align*}

\begin{theorem}
    $\R$ preserves typing and definitional equality: $(t_1, t_2 : \Tm_{\ind}\ \Gamma\ A) \to t_1 = t_2 \to \R t_1 = \R t_2$.
    \begin{proof}
        By $\mta{ap}_\R$.
    \end{proof}
\end{theorem}
$\R$ is not injective in general, because two distinct (by their location in the
global context) data types might be defined to have the same representation.

\begin{theorem}
    $\R$ is a left-inverse of the evident inclusion $i : \lambdaind \hookrightarrow \lambdarep$:
    \[
        (t : \Tm_{\ind}\ \Gamma\ A) \to \R(i t) = t \,.
    \]
    \begin{proof}
        The inclusion produces global contexts in $\lambdarep$ without the $\unrhd$ constructor. Thus no
        items have defined representations. Also, the action of $\R$ on
        the image of $i$ does not invoke the equality reflection rule. With that
        constraint, and by induction on the syntax, $\R \circ i$ is the identity
        function on $\lambdaind$.
    \end{proof}
\end{theorem}

\subsection{Computational irrelevance}\label{sub:irr}

In order to reason about computational irrelevance, we assume that there is
an additional program extraction step $\mathcal{E}$ from $\lambdaind$ into some
simply-typed calculus, denoted by vertical bars $|x|$. As opposed to
$\R$, $\mathcal{E}$ operates on the unquotiented syntax of $\lambdaind$. This
can be justified by interpreting the quotient-inductive constructions from
before into setoids \cite{Kovacs2022-vb}. This kind of transformation is used
because we might want to compile two definitionally equal terms differently. For
example, we might not always want to reduce function application redexes. We
will use the \texttt{monospace} font for terms in $\lambda$.

\begin{definition}
    A function $f : \mta{Tm}\ \Gamma\ (\Pi\ A\ B)$, is \emph{computationally irrelevant} if
    $|\R A| = |\R B|$ and $|\R f| = \texttt{id}$.
\end{definition}

\begin{theorem}
	The type former $\MRepr{}$ is injective up to internal isomorphism, i.e.
	\begin{equation}
	\Tm\ \Gamma\ (\mta{Id}\ (\mta{Repr}\ T)\ (\mta{Repr}\ T')) \to \Tm\ \Gamma\ (\mta{Iso}\ T\ T')
	\end{equation}
	Moreover, this isomorphism is computationally irrelevant.
	\begin{proof}
	For the input proof $p$, the forward direction is
	$\lambda x.\ \Munrepr_{T'}\ (\mta{J}\ \mta{id}\ (\Mrepr\ x)\ p)$
	and the backward direction is
	$\lambda x.\ \Munrepr_{T}\ (\mta{J}\ \mta{id}\ (\Mrepr\ x)\ (\mta{sym}\
	p))$. The coherence holds definitionally by
    \begin{align*}
	&\Munrepr_{T'}\ (\mta{J}\ \mta{id}\ (\Mrepr\ (\Munrepr_{T}\ (\mta{J}\ \mta{id}\ (\Mrepr\ x)\ (\mta{sym}\ p))))\ p) \\
	&= \Munrepr_{T'}\ (\mta{J}\ \mta{id}\ (\mta{J}\ \mta{id}\ (\Mrepr\ x)\ (\mta{sym}\ p))\ p) \text{ by }{\mta{reprl}} \\
    &= \mta{J}\ \mta{id}\ (\mta{J}\ \mta{id}\ x\ (\mta{sym}\ p))\ p \text{ by }{\mta{unrepr-J}\times 2 + \mta{reprr}} \\
    &= x \text{ by }{(\mta{uip} + \mta{J-elim})\times2} \,,
    \end{align*}
	and similarly for the other side. After applying $\R$, we get $\lambda x.\
	\mta{J}\ \mta{id}\ x\ p =_{\mta{uip}+\mta{J-elim}} \lambda x.\ x$ on both sides.
	\end{proof}
\end{theorem}

Consider extending our languages with usage-aware
subset $\Sigma$-types
\[
\{ \_ \mid \_ \} : (A : \Ty\ \Gamma) \to \Ty\ (\Gamma \rhd A) \to \Ty\ \Gamma
\]
in such a way that $\MRepr$ and $\R$ preserve them, but the extraction
step erases the right component, i.e. $|\{A \mid B\}| = |A|$, $|(x, y)| = |x|$ and $|\pi_1 x| =
|x|$.\footnote{This can be implemented using quantitative type theory for example.}
Suppose we have an inductive family $G : \mta{data}\ (\bullet \rhd I)\ T_G
\in \Sigma$ over some index type $I$, and an inductive type $F : \mta{data}\ \bullet\
T_F \in \Sigma$ such that $G$ is represented by a refinement $f : \Tm\
(\Sigma,\bullet)\ (\Pi\ (\mta{D}\ F)\ I)$ of $F$,
\[
    \mta{datarep}\ (i.\ \{ x : \mta{D}\ F \mid \mta{Id}\ (f\ x)\ i \}, r, Q) \in_G \Sigma \,.
\]
Then, we can construct computationally irrelevant functions
\begin{align*}
&\begin{aligned}
&\mta{forget}_i : \Tm\ \Gamma\ (\Pi\ (\mta{D}\ G)[i]\ (\mta{D}\ F)) \\
&\mta{forget}_i = \lambda g.\ \pi_1\ (\mta{repr}\ g)
\end{aligned} \quad \begin{aligned}
&\mta{remember} : \Tm\ \Gamma\ (\Pi\ (x : \mta{D}\ F)\ (\mta{D}\ G)[f\ x]) \\
&\mta{remember} = \lambda x.\ \mta{unrepr}\ (x, \mta{refl}) \,.
\end{aligned}
\end{align*}
Clearly $|\R\ \mta{forget}_i| = |\R\ \mta{remember}| = \texttt{id}$.
