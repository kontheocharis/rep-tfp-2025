\section{A type system for data representations}\label{sec:type-system}

In this section, we develop an extension of dependent type theory with inductive
families and custom data representations. We start in \cref{sub:algebras} by
exploring the semantics of data representations in terms of inductive algebras
for signatures. In \cref{sub:lambdadata} we define a core language $\lambdadata$
with these features. The base theory is intensional Martin-L\"of type theory
(\lambdamltt) \cite{Martin-Lof1984-pz} with a single universe $\univ : \univ$.
We omit considerations of consistency and universe hierarchy, though these can
be added if needed. In \cref{sub:lambdadata}, we define the modality $\MRepr$
that allows us to convert between inductive types and their representations.
Finally, in \cref{sub:translation} we define a translation from $\lambdadata$ to
\emph{extensional} \lambdamltt, which `elaborates away' all inductive families
to their representations. All of the examples in the paper so far have been
written in a surface language that elaborates to $\lambdadata$.

% We work in an extensional metatheory with a small universe $\Set$, $(a : A)
% \times B$ for dependent pairs, $(a : A) \to B$ for dependent products, and $=$
% for equality, and an Agda-like syntax.
The languages we work with are defined in an intrinsically well-formed manner \cite{Altenkirch2016-zc}
as a setoid over definitional equality, with de-Bruijn
indices for variables. Weakening of terms is generally left implicit to reduce
syntactic noise, and often named notation is used when indices are
implied. We use $(a : A) \to B$ for dependent functions, $(a : A) \times B$ for
dependent pairs, $a \equiv_A a'$ for propositional equality, and $a = a' : A$
for definitional equality. Substitution is denoted with square brackets: if
$\Gamma, A \vdash B$ and $\Gamma \vdash a : A$ then $\Gamma \vdash B[a]$. We
also notationally identify elements of the universe $A : \univ$ with types $A
\type$.
Besides the
usual judgement forms of \lambdamltt, we also have telescopic judgement forms
\begin{definitions}
$\Gamma \vdash \Delta \tel$                & $\Delta$ is a telescope in $\Gamma$ \\
$\Gamma \vdash \delta :: \Delta$           & $\delta$ is a spine (list of terms) matching telescope $\Delta$
\end{definitions}
with accompanying rules shown in \cref{fig:tel-rules}.

\begin{figure}[H]
  \vspace{-1em}
  \begin{mathpar}
  \inferrule[\htarget{Tel-Empty}]{ }{\Gamma \vdash \bullet \tel}
  \and
  \inferrule[\htarget{Tel-Extend}]{\Gamma \vdash A \type \\ \Gamma, A \vdash \Delta \tel}{\Gamma \vdash (A, \Delta) \tel}
  \\
  \inferrule[\htarget{Spine-Empty}]{ }{\Gamma \vdash (\,) :: \bullet} \and
  \inferrule[\htarget{Spine-Extend}]{\Gamma \vdash a : A \\ \Gamma \vdash \delta : \Delta[a]}{\Gamma \vdash (a, \delta) :: (A, \Delta)}
  \vspace{-1em}
  \end{mathpar}
  \caption{Rules for forming telescopes and spines.}
  \label{fig:tel-rules}
  \vspace{-1em}
\end{figure}

Extending contexts by telescopes (such as $\Gamma, \Delta$) is defined by
induction on telescopes. We write $\Delta \to X$ for an iterated function type
with codomain $\Gamma, \Delta \vdash X$, and $(\delta :: \Delta) \to X[\delta]$
when names are highlighted. We will often use the notation $\delta.y$ to extract
a certain index $y$ from a spine $\delta$. This is used when we define
telescopes using named notation. For example, if $\delta :: (\textit{X} : A \to
\univ, \textit{y} : (a : A) \to X\ a)$, then $\delta.X : A \to \univ$ and
$\delta.y : (a : A) \to \delta.X\ a$.


\newcommand{\ValidCase}{\mta{ValidCase}}

\subsection{Algebraic signatures}

A representation of a data type must be able to emulate the behaviour of the
original data type. In turn, the behaviour of the original data type is
determined by its elimination, or induction principle. This means that a
representation of a data type should provide an implementation of induction of
the same `shape' as the original. Induction can be characterised in terms of
algebras and displayed algebras of algebraic signatures \cite{Adamek2010-ls,Kovacs2023-gq}.
Algebraic signatures consist of a list of operations, each with a specified
arity. There are many flavours of algebraic signatures with varying degrees of
expressiveness. For this paper, we are interested in the ones which can
be used as a syntax for defining inductive families in a type theory. Thus, we define
two new judgement forms
\begin{definitions}
$\Gamma \vdash S \sig \Delta$    & $S$ is a signature with indices $\Delta$ in context $\Gamma$  \\
$\Gamma \vdash O \op \Delta$     & $O$ is an operation with indices $\Delta$ in context $\Gamma$
\end{definitions}
with accompanying rules shown in \cref{fig:tel-rules}.
Signatures are lists of operations, and operations build up constructor types.

\enlargethispage{\baselineskip}

\begin{figure}[H]
  \begin{mathpar}
    \inferrule[\htarget{Sig-Empty}]{\Gamma \vdash \Delta \tel}{\Gamma \vdash \epsilon \sig \Delta}
    \and
    \inferrule[\htarget{Sig-Extend}]{\Gamma \vdash \Delta \tel \\ \Gamma \vdash O \op \Delta \\ \Gamma \vdash S \sig \Delta}{\Gamma \vdash (O \lhd S) \sig \Delta}
    \\
    \inferrule[\htarget{Op-Ext}]{\Gamma \vdash A \type \\ \Gamma, A \vdash O \op \Delta}
    {\Gamma \vdash (A\ \to\external O) \op \Delta} \and
    \inferrule[\htarget{Op-Int}]{\Gamma \vdash \delta :: \Delta \\ \Gamma \vdash O \op \Delta}
    {\Gamma \vdash (\iota\ \delta \to\internal O) \op \Delta} \and
    \inferrule[\htarget{Op-Ret}]{\Gamma \vdash \delta :: \Delta}
    {\Gamma \vdash (\iota\ \delta) \op \Delta}
    \end{mathpar}
  \caption{Rules for forming signatures and operations.}
\end{figure}

Each signature is described by an associated telescope of indices $\Delta$, and a
\emph{finite list} of operations:
\begin{itemize}
    \item $(x : A) \to\external O[x]$, a (dependent) abstraction over some external type $A$, of another operation $O$.
    \item $\iota\ \delta \to\internal \ O$, an
      abstraction over a recursive occurence of
      the object being defined, with indices $\delta$, of another operation
      $O$.
    \item $\iota\ \delta$, a constructor of the object being defined, with indices $\delta$.
\end{itemize}

\begin{example}[Natural numbers]\label{ex:nat-sig}
The signature for natural numbers is indexed by the empty telescope $\bullet$.
It is defined as $\Gamma \vdash (\iota\ (\,) \lhd \iota\ (\,) \to\internal
\iota\ (\,) \lhd \epsilon) \sig \bullet$. We can add labels to aid readability,
omit index spines if they are empty, and omit the final $\epsilon$ from
signatures:
\[
\Gamma \vdash (\textit{zero} : \iota \lhd \textit{succ} : \iota\ \to\internal
\iota) \sig \bullet \,.
\]
\end{example}

\begin{example}[Vectors]\label{ex:vec-sig}
The signature for vectors of elements of type $T$ and length $n$ is indexed by
the telescope $(T : \univ, n : \mathbb{N})$, defined as
\begin{align*}
\Gamma \vdash (&\n{nil} : (T : \univ) \to\external \iota\ T\ \n{zero}\ \lhd \\
&\n{cons} : (T : \univ) \to\external (n' : \mathbb{N}) \to\external (t : T)
\to\external \iota\ T\ n' \to\internal \iota\ T\ (\n{succ}\ n')) \\ &\sig (T :
\univ, n : \mathbb{N}) \,.
\end{align*}
Later (\cref{sub:constructing-inductive-families}) we will see how we can use the signature in \cref{ex:nat-sig} to define
the type of natural numbers $\Gamma \vdash \mathbb{N} \type$.
\end{example}

Notice that this syntax only allows occurrences of $\iota$ in positive
positions, which is a requirement for inductive types. Different classes of
algebraic signatures, theories and quantification are explored in detail by
Kov\'acs \cite{Kovacs2023-gq}. We make no distinction between parameters and
indices, though it is possible to add parameters by augmenting the syntax for
signatures with an extra telescope that must be uniform across operations.

\subsection{Interpreting signatures in the type theory} \label{sub:algebras}

In order to make use of our definition for algebraic signatures, we would like
to be able to interpret their structure as types in the type theory we are working
with.

\subsubsection{Algebras}

An \emph{algebra} for a signature $\Gamma \vdash S \sig \Delta$ and carrier type
$\Gamma, \Delta \vdash X \type$ interprets the structure of $S$ in terms of the
type $X$. Concretely, this produces a telescope which matches the structure of
$S$ but replaces each occurrence of $\iota\ \delta$ with $X[\delta]$. The
function arrows $\to\internal$ and $\to\external$ in $S$ are interpreted as the
function arrow $\to$ of the type theory.

\begin{example}[Natural numbers]\label{ex:nat-alg}
An algebra for the signature of natural numbers (\cref{ex:nat-sig}) over a carrier $\Gamma \vdash N \type$ is a spine matching
the telescope \[\Gamma \vdash (\n{zero}: N,\ \n{succ}: N \to N) \tel.\]
\end{example}

\begin{example}[Vectors]\label{ex:vec-alg}
An algebra for the signature of vectors (\cref{ex:vec-alg}) over a carrier $\Gamma, T : \univ, n : \mathbb{N} \vdash V \type$ is a spine matching
the telescope
\begin{align*}
 \Gamma \vdash (&\n{nil} : (T : \univ) \to V[T, \n{zero}], \\
&\n{cons} : (T : \univ) \to (n' : \mathbb{N}) \to (t : T) \to (ts : V[T,n']) \to V[T, \n{succ}\ n']) \tel.
\end{align*}
\end{example}

\subsubsection{Induction}

The actual type of natural numbers $\Gamma \vdash \mathbb{N} \type$ is the
carrier of an algebra over the signature of natural numbers. In particular, the
`best' such algebra: one whose operations do not forget any information. In the
language of category theory, this is the initial algebra in the category of
algebras over the signature of natural numbers. An equivalent formulation of
initial algebras is algebras which support \emph{induction}, which is more
suitable for our (syntactic) purposes. An algebra $\alpha :: (\textit{zero}: X,\
\textit{succ}: X \to X)$ for natural numbers supports induction if:

\begin{quote}
For any type family $X \vdash Y \type$, if we can construct a $\textit{zero}_Y :
Y[\alpha.\textit{zero}]$ and a $\textit{succ}_Y : (x : X) \to Y[x] \to
Y[\alpha.\textit{succ}\ x]$, then we can construct a $\sigma[x] : Y[x]$ for all
$x : X$.
\end{quote}

The type family $Y$ is commonly called the \emph{motive}, and $(\textit{zero}_Y,
\textit{succ}_Y)$ are the \emph{methods}. The produced term family $x : X \vdash
\sigma : Y[x]$ is a \emph{section} of the type family $Y$. Induction also
requires that the section acquires its values from the provided methods. This
means that
\[
\sigma[\alpha.\textit{zero}] = \textit{zero}_Y \qquad \sigma
[\alpha.\textit{succ}\ x] = \textit{succ}_Y\ x\ \sigma[x].
\]
We call these \emph{coherence conditions}. A section that satisfies these
conditions is called a \emph{coherent section}. These equations might or might
not hold definitionally. In the former case, we have the definitional equalities
\begin{align*}
\Gamma &\vdash \sigma[\alpha.\textit{zero}] = \textit{zero}_Y : Y[\alpha.\textit{zero}] \\
\Gamma, x : X &\vdash \sigma[\alpha.\textit{succ}\ x] = \textit{succ}_Y\ x\ \sigma[x] : Y[\alpha.\textit{succ}\ x].
\end{align*}
In the latter case, we have a spine of propositional equality witnesses
\begin{align*}
\Gamma \vdash \sigma_{\text{coh}} :: (&\n{zero}_{\text{coh}} :
\sigma[\alpha.\textit{zero}] \equiv \textit{zero}_Y, \\
&\n{succ}_{\text{coh}} : (x : X) \to \sigma[\alpha.\textit{succ}\ x] \equiv
\textit{succ}_Y\ x\ \sigma[x]).
\end{align*}

\subsubsection{Displayed algebras}

Notice that the methods $(\textit{zero}_Y, \textit{succ}_Y)$ look like an
algebra for the signature of natural numbers too, but their carrier is now a
type family over another algebra carrier $X$, and the types of the operations
mention both $X$ and $Y$, using $\alpha$ to go from $\Delta$ to $X$. These are
\emph{displayed algebras}. In general, a displayed algebra for a signature
$\Gamma \vdash S \sig \Delta$, algebra $\alpha$ for $S$ over carrier $\Gamma,
\Delta \vdash X \type$, and carrier family $\Gamma, \Delta, X \vdash Y \type$,
interprets the structure of $S$ in terms of both $X$ and $Y$. This produces a
telescope which matches the structure of $S$ but replaces each recursive
occurrence $\iota\ \delta$ with an argument $x : X$ as well as an argument $y :
Y[x]$. Each operation returns a $Y$ with indices computed from $\alpha$. Again,
the function arrows in $S$ are interpreted as function types in the type theory.

\begin{example}[Vectors]\label{ex:vec-disp-alg}
A displayed algebra for an algebra $(\n{nil}, \n{cons})$ for vectors
(\cref{ex:vec-alg}) over a carrier family $\Gamma, T : \univ, n : \mathbb{N}, v
: V[T, n] \vdash W \type$ is a spine matching
the telescope
\begin{align*}
 \Gamma \vdash (&\n{nil}_W : (T : \univ) \to W[T, \n{zero}, \n{nil}\ T], \\
&\n{cons}_W : (T : \univ) \to (n' : \mathbb{N}) \to (t : T) \to (ts : V[T,n']) \\
&\qquad \to (ts_W : W[T, n', ts]) \to W[T, \n{succ}\ n', \n{cons}\ T\ n'\ t\ ts]) \tel.
\end{align*}
\end{example}

In practice, in a call-by-value setting, it is desirable for the inductive
hypotheses of a displayed algebra ($\n{ts}_W$ above) to be
\emph{lazy} values. This improves performance when the inductive hypotheses are
not needed. We leave this as an implementation detail.

Finally, we come to the central definition
that classifies the algebras which
support induction:
\begin{definition}
An algebra is \emph{inductive} if every displayed algebra over it has a coherent section.
\end{definition}
The elimination rule for inductive data types in programming languages is
exactly this: given any motive and methods (a displayed algebra), we get a
dependent function from the type of the scrutinee to the type of the motive (a
section). Furthermore this function satisfies some appropriate computation rules:
when we plug in a constructor, we get the result of the method corresponding to it (the coherence conditions).
Usually in programming languages, these conditions hold definitionally, as they are the primary means
of computation with data.

% \subsubsection{Uniqueness of inductive algebras}

% As mentioned earlier, inductive algebras are equivalent to initial algebras.
% Since initial objects are unique up to isomorphism, this suggests the following result:

% \begin{theorem}\label{thm:unique-inductive-algebras}
% For any given signature $S$, if we can construct two inductive algebras for $S$,
% over carriers $X$ and $X'$, then there exists an isomorphism of types $X \simeq X'$. Moreover,
% this isomorphism extends to the category of $S$-algebras, meaning it respects the structure of $S$.
% \begin{proof}
% See \cref{app:algebras}.
% \end{proof}
% \end{theorem,

\subsection{Defining algebras and friends}

In order to utilise these constructions for our type system, we now explicitly define
the follwing objects:
\begin{definitions}
$\Gamma \vdash S\A\ X \tel$ & Algebras for a signature $\Gamma \vdash S \sig \Delta$ over a carrier $\Gamma, \Delta \vdash X \type$. \\
$\Gamma \vdash \alpha\D\ Y \tel$ & Displayed algebras for an algebra $\Gamma \vdash \alpha :: S\A\ X$ over a motive $\Gamma, \Delta, X \vdash Y \type$. \\
$\Gamma \vdash \beta\COH\ \sigma \tel$ & Propositional coherence for a section $\Gamma, \Delta, X \vdash \sigma : Y$ of a displayed algebra $\Gamma \vdash \beta :: \alpha\D\ Y$.
\end{definitions}
All constructions labelled with superscripts are not part of the syntax of the
type system, but rather functions in the metatheory which compute syntactic
objects such as telescopes.

The algebras for a signature are defined
by case analysis on $S$:
\begin{align*}
&\boxed{\Gamma \vdash S\A\ X \tel} \\
&\epsilon\A\ X = \bullet \qquad (O \lhd S')\A\ X = ((\nu :: O\IN\ X) \to X[\nu\OUT],\ {S'}\A\ X) \,.
\end{align*}
An empty signature $\epsilon$ produces an empty telescope, while an extended
signature $O \lhd S'$ produces a telescope extended with a function
corresponding to $O$. This function goes from the inputs of $O$ interpreted in
$X$, to $X$ evaluated at the output indices.
The inputs and outputs of each operation $O$ in an algebra are defined by case
analysis on $O$:
\begin{block}
\setlength{\tabcolsep}{10pt}
\begin{tabular}{ll}
$\boxed{\Gamma \vdash O\IN\ X \tel}$ & \boxed{\Gamma \vdash \{O\}\ \nu\OUT :: \Delta} \\[1em]
{$\begin{aligned}
&(A\to\external O')\IN\ X = (a : A,\ O'[a]\IN\ X) \\
&(\iota\ \delta \to\internal O')\IN\ X = (x : X[\delta],\ {O'}\IN\ X) \\
&(\iota\ \delta)\IN\ X = \bullet
\end{aligned}$}
&
{$\begin{aligned}
&\{O = A \to\external O'\}\ (a, \nu')\OUT = {\nu'}\OUT \\
&\{O = \iota\ \delta \to\internal O'\}\ (x,\ \nu')\OUT = {\nu'}\OUT  \\
&\{O = \iota\ \delta\}\ (\,)\OUT = \delta \,.
\end{aligned}$}
\end{tabular}
\end{block}

A similar construction can be performed for displayed algebras over algebras.
Displayed algebras are defined by case analysis on $S$, which is an implicit parameter of $-\D$:
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \alpha\D\ Y \tel} \\
& \{S = \epsilon\}\ (\,)\D\ Y = \bullet \\
&\{S = O \lhd S'\}\ (\alpha_O, \alpha')\D\ Y = ((\mu :: \alpha_O\DI\ Y) \to Y[\mu\DO],\ {\alpha'}\D\ Y) \,.
\end{align*}
We omit the definitions of $-\DI$ and $-\DO$ and
\href{https://github.com/kontheocharis/rep-agda/blob/e6bd34adaab630f5787c63a95fa86869f6c19da4/TT/Sig.agda\#L107}{refer to the Agda formalisation},
but they are similar to
the definitions of $-\IN$ and $-\OUT$.

Next we define the coherence conditions for a displayed algebra as a telescope
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \{\alpha\}\ \beta\COH\ \sigma \tel} \\
& \{S = \epsilon\}\ \{\alpha = (\,)\}\ (\,)\COH\ \sigma = \bullet \\
& \{S = O \lhd S'\}\ \{\alpha = (\alpha_O, \alpha')\}\ (\beta_O, \beta')\COH\ \sigma \\
&\qquad = ((\nu :: O\IN\ X) \to \sigma[\alpha_O\ \nu] \equiv \beta_O\ (\sigma \, \$ \, \nu),\  {\beta'}\COH\ \sigma) \,.
\end{align*}
The notation $\sigma \, \$\, \nu$ applies the section $\sigma$ to the input $\nu$,
yielding a displayed input by sampling the section to get the inductive
hypotheses.

Now we can define induction for an algebra $\alpha$ as a type
\begin{align*}
&\boxed{\Gamma \vdash \{S\}\ \alpha\IND \type} \\
&\{S\}\ \alpha\IND = (Y : (\delta :: \Delta) \to X[\delta] \to \univ) \to (\beta :: \alpha\D\ (\delta.\ x.\ Y\ \delta\ x)) \\
&\qquad\to (\sigma : (\delta :: \Delta) \to (x : X[\delta]) \to Y\ \delta\ x)) \times (\rho :: \beta\COH\ (\delta.\ x.\ \sigma\ \delta\ x)) \,,
\end{align*}
where $Y$ is the motive, $\beta$ are the methods, and $\sigma$ is the output section which must
satisfy the propositional coherence conditions $\rho$.
Finally, we can package an inductive algebra over a signature as a telescope
\begin{align*}
&\boxed{\Gamma \vdash S\INDA \tel} \\
&S\INDA = (X : \Delta \to \univ,\ \alpha :: S\A\ (\delta.\ X\ \delta),\ \kappa : \alpha\IND) \,,
\end{align*}
by collecting the carrier $X$, algebra $\alpha$ and induction $\kappa$ all together.

\subsection{Constructing inductive families}\label{sub:constructing-inductive-families}

We now extend intensional \lambdamltt with a type for inductive families, which we
denote $\Mdata_\Delta\ S\ \gamma$. This type defines an inductive family
matching a signature $S$ with indices $\Delta$, together with an inductive
algebra $\gamma$ which `implements' the signature $S$. Notice that this is
different to the usual way that inductive families are defined in type theory,
for example W-types \cite{Abbott2004-va}, where all we need to provide is
a signature.\footnote{
Notice that the data defining a W-type $(A : \univ, B : A \to \univ)$ can be viewed as a kind of signature, where $A$ describes the
operations and their non-recursive parameters, while $B$ describes the arities of the recursive parameters.}
Here, we must also implement the signature and prove
the induction principle by providing $\gamma$, rather than it being `built-in' to
the type theory. For example, if the type theory has W-types, then we can
construct $\gamma$ using an appropriate W-type. In effect, this will later allow us to
translate away inductive definitions to their defined representations.
This leads to the formal definition of a representation:
\begin{definition}
A \emph{representation} of a signature $S$ is an inductive algebra for $S$.
\end{definition}

In \cref{fig:data-rules} we define the $\Mdata$ type, and its corresponding
introduction, elimination, and computation rules.
Constructors form an algebra for the signature $S$ over
$\Mdata_\Delta\ S\ \gamma$, denoted by $\Mctor_S = (\Mctor_{S.O})_{O \in S}$.
Similarly, the eliminator forms a coherent section over the constructor algebra,
which holds definitionally.

\begin{figure}[t]
\begin{mathpar}
\inferrule[\htarget{Data-Form}]
{\Gamma \vdash S \sig \Delta \\ \Gamma \vdash \gamma :: S\INDA \\ \Gamma \vdash \delta :: \Delta}
{\Gamma \vdash \Mdata_\Delta\ S\ \gamma\ \delta \type} \and
\inferrule[\htarget{Data-Intro}]
{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
{\Gamma \vdash \Mctor_{S.O}\ \nu : \Mdata_\Delta\ S\ \gamma\ \nu\OUT} \and
\inferrule[\htarget{Data-Elim}]
{\Gamma,\ \delta :: \Delta,\ \Mdata_\Delta\ S\ \gamma\ \delta \vdash M \type \\
\Gamma \vdash \beta :: \Mctor_S\D\ M \\
\Gamma \vdash \delta :: \Delta \\
\Gamma \vdash x : \Mdata_\Delta\ S\ \gamma\ \delta}
{\Gamma \vdash \Melim_S\ M\ \beta\ \delta\ x : M[\delta, x]} \and
\inferrule[\htarget{Data-Comp}]
{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma) \\
\Gamma,\ \delta :: \Delta,\ \Mdata_\Delta\ S\ \gamma\ \delta \vdash M \type \\
\Gamma \vdash \beta :: \Mctor_S\D\ M}
{\Gamma \vdash \Melim_S\ M\ \beta\ \nu\OUT\ (\Mctor_{S.O}\ \nu) = \beta_O\ (\Melim_S\ M\ \beta \ \$\ \nu) : M[\nu\OUT, \Mctor_{S.O}\ \nu]}
\end{mathpar}
\caption{Rules for data types, constructors and eliminators. We write $O \in S$
to indicate that $O$ is an operation in the signature $S$. We write $\alpha_O$
to extract the telescope element corresponding to operation $O$ from the algebra
$\alpha$ for $S$.}
\label{fig:data-rules}
\end{figure}

One might think, what do we gain by adding $\Mdata$ to the theory? If we can
provide an inductive algebra $\gamma$ for a signature $S$ ourselves, then why
not use $\gamma$ directly? The reason is that by having a primitive for
inductive types, we can take advantage of their properties in an extensional
way. For example, an induction principle suggests that the constructors
corresponding to each method are disjoint. Since constructors $\Mctor$ are
primitive terms in the theory, we can make use of this when formulating a
unification algorithm. Aside from disjointness, we can also rely on other
properties such as injectivity, acyclicity, and `no-confusion'. McBride
\cite{McBride2006-fp} originally explored the properties which arise from the
existence of induction principles, or equivalently, initiality.

For example, if we have an inductive algebra $(\n{N}, \n{zero}_{\n{N}},
\n{succ}_{\n{N}}, \n{elim}_{\n{N}})$ for the natural numbers signature
$\n{NatSig}$ (\cref{ex:nat-sig}), we can prove propositionally that for all $x : \n{N}$,
$\n{zero}_{\n{N}} \neq \n{succ}_{\n{N}}\ x$, by invoking $\n{elim}_{\n{N}}$.
However, the typechecker does not know this fact; it is not derivable as a
definitional equality contradiction. However, it \emph{is} derivable
definitionally that for all $x : \mathbb{N}$, $\Mctor_{\n{zero}} \neq
\Mctor_{\n{succ}}\ x$, where $\mathbb{N} = \Mdata\ {\n{NatSig}}\ (\n{N},
\n{zero}_{\n{N}}, \n{succ}_{\n{N}}, \n{elim}_{\n{N}})$ because the
syntax does not equate $\Mctor_i$ and
$\Mctor_j$ unless $i = j$.

Importantly, the existence of $\Mdata$ enables the use of
\emph{dependent pattern matching} on its inhabitants. Nested pattern matching on
$\mathbb{N}$, for example, can be elaborated to invocations of
$\Melim_{\mathbb{N}}$, which has the expected computation rules as shown in
\cref{fig:data-rules}. Converting dependent pattern matching to eliminators has
been explored in depth by Goguen, McBride and McKinna \cite{Goguen2006-sy}, as
well as by Cockx and Devriese \cite{Cockx2018-bv} in absence of Axiom K.

\subsection{Reasoning about representations} \label{sub:lambdadata}

So far we are able to construct data types using the $\Mdata_\Delta\ S\ \gamma$
type constructor. These data types are themselves implemented in terms of
inductive algebras. However, the rules for data types do not utilise them. We
would like to be able to relate data types to their underlying inductive
algebras. One reason is to avoid unnecessary
computation. If we have a type $X$ that is the carrier of two inductive algebras
$(X, \alpha, \kappa)$ and $(X, \alpha', \kappa')$ for signatures $S$ and
$S'$ respectively, then we can form the data types $D = \Mdata_\Delta\ S\ (X,
\alpha, \kappa)$ and $D' = \Mdata_\Delta\ {S'}\ (X, \alpha', \kappa')$ and make
use of the structural properties of initiality. However, we would also like to
be able to freely convert between $X$, $D$ and $D'$ without incurring any
runtime cost. After all, $D$ and $D'$ are meant to be translated away to their
underlying representation, $X$. This argument can also be made in the context of
theorem proving: sometimes it is easier to prove a property about $D$ or $D'$,
due to their structure, but we should be able to `transport' the property to
$X$.

To make use of these conversions in a computationally-irrelevant manner,
while still retaining the fact that $D$, $D'$ and $X$ are distinct types,
we introduce a modality
$$
\MRepr : \univ \to \univ ,
$$
which takes types to their representations. It comes with two term formers
$\Mrepr$ and $\Munrepr$, which are definitional inverses of each other. We
highlight the main rules of $\MRepr$ in \cref{fig:repr-rules}.

\begin{figure}[H]
\begin{mathpar}
\inferrule[\htarget{Repr-Form}]{\Gamma \vdash A \type}{\Gamma \vdash \MRepr\ A \type} \and
\inferrule[\htarget{Repr-Intro}]{\Gamma \vdash a : A}{\Gamma \vdash \Mrepr\ a : \MRepr\ A} \and
\inferrule[\htarget{Repr-Elim}]{\Gamma \vdash a : \MRepr\ A}{\Gamma \vdash \Munrepr\ a : A} \and
\inferrule[\hypertarget{Repr-Id1}{$\axiom{Repr-Id}_1$}]{\Gamma \vdash a : \MRepr\ A}
{\Gamma \vdash \Mrepr\ (\Munrepr\ a) = a : \MRepr\ A} \and
\inferrule[\hypertarget{Repr-Id2}{$\axiom{Repr-Id}_2$}]{\Gamma \vdash a : A}
{\Gamma \vdash \Munrepr\ (\Mrepr\ a) = a : A} \and
\inferrule[\htarget{Repr-Data}]{\Gamma \vdash S \sig \Delta \\ \Gamma \vdash \gamma :: S\INDA \\ \Gamma \vdash \delta :: \Delta}
{\Gamma \vdash \MRepr\ (\Mdata_\Delta\ S\ \gamma\ \delta) = \gamma.X\ \delta}
\end{mathpar}
\caption{Introduction and elimination forms, as well as computation rules
for the $\MRepr$ modality.}
\label{fig:repr-rules}
\end{figure}

These rules allow us to go between a data type $D = \Mdata_\Delta\ S\ \gamma\
\delta$ and its representation $\gamma.X\ \delta$. In the translation to
extensional \lambdamltt that we are yet to define, this modality is also
translated away. Indeed, its purpose is purely intensional: we do not want to
equate $\Mdata_\Delta\ S\ \gamma$ with $\gamma.X$ because that would render
conversion checking undecidable, but we still want to make use of the fact that
these types are `the same'. In other words, $\MRepr\ A \simeq A$ but not
$\MRepr\ A = A$. All the contextual machinery of general modal type systems
\cite{Gratzer2020-kf} is not necessary here because this modality is fibred over
contexts so it presents as a type former.

One might hope for additional computation rules. For example, the representation
of a constructor should be equal to the underlying algebra element of the
constructor type's representation:\footnote{When we write $\Mrepr\ \nu$ we mean
to apply $\Mrepr$ to all recursive occurences (all places that $\iota$ appears
in the domain of $O$).} \[\Mrepr\ (\Mctor_{S.O}\ \nu) = \gamma.\alpha_O\ (\Mrepr
\ \nu) \,.\] Unfortunately, having this as a computation rule would render
conversion checking undecidable, because if one applies $\mta{unrepr}$ to a term
$\Mrepr\ (\Mctor_{S.O}\ \nu)$ which has already been reduced to its
representation, $\mta{unrepr}\ (\gamma.\alpha_O\ (\Mrepr\ \nu))$, there is no
clear way to decide that this is convertible to $\Mctor_{S.O}\ \nu$ even though
the definitional equality rules would imply that it is (due to
\hyperlink{Repr-Id2}{$\axiom{Repr-Id}_2$}). Nevertheless, we can still postulate this equality
propositionally, and it is justified by the translation step.

We can also ask for compatibility equations between $\MRepr$ and the rest of
the type formers of \lambdamltt; for example $\MRepr\ ((a : A) \times B[a]) = (a
: \MRepr\ A) \times \MRepr\ B[\Munrepr\ a]$, which can hold definitionally
without breaking conversion. These are given for $\univ$, $\Pi$, $\Sigma$, unit
and identity types in the Agda formalisation.

% \begin{mathpar}
% \inferrule[Repr-Ctor]{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
% {\Gamma \vdash \mta{repr-ctor}_{S.O}\ \nu : \Mrepr\ (\Mctor_{S.O}\ \nu) \equiv \gamma.\alpha_O\ (\Mrepr \  \nu)} \and
% \inferrule[Repr-Elim]{O \in S \\ \Gamma \vdash \nu :: O\IN\ (\Mdata_\Delta\ S\ \gamma)}
% {\Gamma \vdash \mta{repr-elim}_{S}\ M\ \beta\ \delta\ x : \Melim_{S}\ M\ \beta\ \delta\ x
% \equiv (\gamma.\kappa\ (\lambda\delta.\ \lambda x.\ M[\delta, \Munrepr\ x])\ (\Mrepr^*\ \beta)).\sigma\ \delta\ (\Mrepr\ x)}
% \end{mathpar}

\subsubsection{Subuniverse of concrete types}

As described, the modality $\MRepr$ is not idempotent: $\MRepr\
(\MRepr\ A) = \MRepr\ A$ does not always hold. An inductive algebra used as a
representation of a data type might itself be implemented in terms of another
data type, which again reduces under the action of $\MRepr$. A more principled
approach might be to view the image of $\MRepr$ as a subuniverse of $\univ$. The
restriction
$$
\MRepr : \univ \to \univ_C
$$
targets a universe of `concrete' types $\univ_C < \univ$ closed under all
standard type formers, but without any $\Mdata$ types. We can
then require that all inductive algebras $\gamma$ used in the rule
\hyperlink{Data-Form}{\axiom{Data-Form}} must have a concrete carrier $X : \Delta \to \univ_C$. This
does not limit expressivity because we can always wrap any inductive algebra
carrier with $\MRepr$ to bring it down to $\univ_C$. We do not assume this
additional structure for simplicity, but it might be a useful feature in
practice. For example, it would simplify the transitivity example in
\cref{sub:transitivity}.

\subsection{Translating to extensional \langmltt} \label{sub:translation}

We now define a type- and equality-preserving translation step $\R$ shown in
\cref{fig:translation} from \lambdadata to extensional \langmltt, to be
applied during the compilation process. The extensional flavour of \lambdamltt
involves adding the equality reflection rule
\[
\inferrule[\axiom{Reflect $p$}]{\Gamma \vdash p : a =_A a'}{\Gamma \vdash a \equiv a' : A} \,.
\]
General undecidability of conversion is not a problem because type checking is
decidable for $\lambdadata$\footnote{Not formalised in this paper.} and we
apply this transformation after type checking, on fully-typed terms. The
translation is defined over the syntax of $\lambdadata$ \cite{Boulier2017-cm}
such that definitional equality is preserved, shown in
\cref{fig:translation}. $\R$ replaces data types with their underlying inductive
algebras. We use the notation $\Ty$ and $\Tm$ for types and terms respectively,
with a subscript indicating the language.

\begin{figure}
\begin{minipage}[t]{0.5\textwidth}
\begin{align*}
% &\boxed{\R : \Con_{\langdata} \to \Con_{\langmltt}} \\
% &\boxed{\R : \Sub_{\langdata}\ \Gamma\ \Gamma' \to \Sub_{\langmltt}\ \R \Gamma\ \R \Gamma'} \\
% &\text{(recurse with $\R$)} \\[1em]
&\boxed{\R : \Ty_{\langdata}\ \Gamma \to \Ty_{\langmltt}\ \R \Gamma} \\
&\R (\MRepr\ A) = \R A \\
&\R (\Mdata_{\Delta}\ S\ \gamma\ \delta) = \R (\gamma.X)\ \R \delta \\
&\text{(otherwise recurse with $\R$)}
\end{align*}
\end{minipage}%
\begin{minipage}[t]{0.5\textwidth}
\begin{align*}
&\boxed{\R : \Tm_{\langdata}\ \Gamma\ A \to \Tm_{\langmltt}\ \R \Gamma\ \R A} \\
&\R (\Mrepr\ t) = \R t \\
&\R (\Munrepr\ t) = \R t \\
&\R (\Mctor_{S.O}\ \{\gamma\}\ \nu) = \R (\gamma.\alpha_O)\ \R\nu \\
&\R (\Melim_{S}\ \{\gamma\}\ M\ \beta\ \delta\ x)  \\ &\qquad = (\R (\gamma.\kappa)\ \R M\ \R \beta).\sigma\ \R\delta\ \R x \\
&\text{(otherwise recurse with $\R$)}
\end{align*}
\end{minipage}
\caption{Translation of $\lambdadata$ to $\lambdamltt$, replaces data types
with their underlying inductive algebras, and eliminators by the induction
principle provided by representations.}
\label{fig:translation}
\end{figure}

All the mappings above are structurally recursive, demonstrated by the construction
of a  \emph{model} of \lambdadata in the Agda formalisation. The translation is
extended to contexts, substitutions, telescopes and spines pointwise, and
the rest of the syntax is preserved: $\R((a : A) \to B[a]) = (a : \R A) \to (\R
B)[a]$ etc. All $\Mdata$ types are translated to the carriers of their inductive
algebras. Invocations of $\MRepr$ are removed. One can view $\MRepr$ as locally
applying $\R$ to a part of the program. The definitional equality preservation
by $\R$ is shown in \cref{fig:translation-eq}. The isomorphism of
$\Mrepr/\Munrepr$, as well as the rule \hyperlink{Repr-Data}{\axiom{Repr-Data}} are preserved by
metatheoretic reflexivity on the other side, since all representation operators
are erased. Coherence rules for eliminators are preserved by reflecting the
propositional coherence rules provided by their defined representations.

\begin{figure}[H]
\begin{minipage}[t]{0.45\textwidth}
\begin{align*}
% &\boxed{\apR^\Con : \Gamma \approx_{\langdata} \Gamma' \to \R \Gamma \approx_{\langmltt} \R \Gamma'} \\
% &\boxed{\apR^{\Sub\ \Gamma\ \Gamma'} : \sigma \approx_{\langdata} \sigma' \to \R \sigma \approx_{\langmltt} \R \sigma'} \\
% &\text{(structurally recurse with $\R$)} \\[1em]
&\boxed{\apR^{\Ty\ \Gamma} : A \approx_{\langdata} A' \to \R A \approx_{\langmltt} \R A'} \\
&\R (\axiom{Repr-Data}\ \{S, \gamma, \Delta\}) \\ &\qquad = \axiom{Refl}\ (\R(\gamma.X)\ \R \delta) \\
&\text{(otherwise recurse with $\apR$)}
\end{align*}
\end{minipage}\hspace{\fill}%
\begin{minipage}[t]{0.45\textwidth}
\begin{align*}
&\boxed{\apR^{\Tm\ \Gamma\ A} : a \approx_{\langdata} a' \to \R a \approx_{\langmltt} \R a'} \\
&\R (\axiom{Repr-Id}_1\ \{a\}) = \axiom{Refl}\ \R a \\
&\R (\axiom{Repr-Id}_2\ \{a\}) = \axiom{Refl}\ \R a \\
&\R (\axiom{Data-Comp}\ \{S, O, \gamma, M, \beta, \nu\})  \\
&\quad = \axiom{Reflect}\ (\R (\gamma.\kappa)\ \R M\ \R \beta).\rho_O\ \R\nu \\
&\text{(otherwise recurse with $\R_\approx$)}
\end{align*}
\end{minipage}
\caption{Equality translation of $\lambdadata$ to extensional $\lambdamltt$. This amounts to
an inductive proof that $\R$ preserves equality.}
\label{fig:translation-eq}
\end{figure}

\newcommand{\mech}[1]{\href{#1}{\textsc{agda}}}

\begin{theorem}[\mech{https://github.com/kontheocharis/rep-agda/blob/0c038fa53d05b796570d0a8c0f0e5e06bedef062/TT/Translation.agda\#L19}]
    $\R$ preserves typing and definitional equality.
\end{theorem}

\begin{theorem}[\mech{https://github.com/kontheocharis/rep-agda/blob/e6bd34adaab630f5787c63a95fa86869f6c19da4/TT/Translation.agda\#L124}]
    $\R$ is a left-inverse of the inclusion $i : \lambdamltt
    \hookrightarrow \lambdadata$:
    \[
    \inferrule{\Gamma \vdash a : A}{\Gamma \vdash \R(i(a)) = a : A} \quad \text{(in extensional \lambdamltt)}.
    \]
    % \begin{proof}
    %     The inclusion produces types without $\Mdata$ or $\MRepr$. Thus, the
    %     action of $\R$ on the image of $i$ does not invoke the equality
    %     reflection rule. With that constraint, and by induction on the syntax,
    %     $\R \circ i$ is the identity function on $\lambdamltt$.
    % \end{proof}
\end{theorem}

\subsubsection{Inductive types in an empty context}

Basic \lambdamltt with dependent functions, pairs and propositional equality as
we have presented here is not sufficient to construct most inductive algebras in
an empty context. Without W-types or fixpoints, we must postulate the induction
principles we have access to, like the example with GMP integers in
\cref{sec:examples}. In practice, we often want to be able to construct
inductive types `from scratch'. For this, we can extend the base theory
with W-types or something similar. One convenient choice is to extend
the syntax of both the source and target languages of $\R$ with a class of data
types like in \cref{fig:data-rules}, but without requiring them to be
implemented by inductive algebras. The advantage is that now we can opt-in when
we want to represent inductive types specially, but otherwise fall back to some
kind of default implementation. The downside is that now the target still
contains inductive types, though this is okay for compilation purposes if we
choose a `sane default', usually tagged unions containing indirections. This is
the approach we take in \superfluid.

\subsection{Computational irrelevance}\label{sub:irr}

In a compiler, there will be an additional program extraction step from the
target of $\R$ into some simply-typed or untyped language, to be handled by the
code-generation backend. We call this language \lambdaprog, and the transformation by
vertical bars $|x|$. As opposed to $\R$, it might not preserve the definitional
equality of the syntax---we might want to compile two definitionally equal terms
differently. For example, we might not always want to reduce function
application redexes. We will use the \texttt{monospace} font for terms in
\lambdaprog.

\newcommand{\Pid}{\ensuremath{\texttt{\textbackslash x => x}}}

\begin{definition}
    A function $\Gamma \vdash f : (a : A) \to B$, is \emph{computationally irrelevant} if
    $|\R A| = |\R B|$ and $|\R f| = \Pid$.
\end{definition}

\begin{theorem}[\mech{https://github.com/kontheocharis/rep-agda/blob/e6bd34adaab630f5787c63a95fa86869f6c19da4/TT/Lemmas.agda\#L147}]
  \label{thm:repr-inj}
	The type former $\MRepr{}$ is injective up to equivalence, i.e.
	\begin{equation}
	\inferrule{\Gamma \vdash p : \MRepr\ T =_{\univ} \MRepr\ T'}{\Gamma\ \vdash \text{conv}_p : T \simeq T'},
	\end{equation}
	 and if $|-|$ erases internal equality reasoning, $\text{conv}_p$ is computationally irrelevant.
	\begin{proof}
	For the input proof $p$, for $\text{conv}_p$ we have
	$\lambda x.\ \Munrepr_{T'}\ (\mta{coe}\ (\Mrepr\ x)\ p)$
	and for $\text{conv}_p^{-1}$ we have
	$\lambda x.\ \Munrepr_{T}\ (\mta{coe}\ (\Mrepr\ x)\ (\mta{sym}\
	p))$. Both directions map to $\lambda x.\ \mta{coe}\ \_\ x$ by $\R$ which becomes \Pid{} by $|-|$.
	\end{proof}
\end{theorem}

In addition, we can reason about the computational irrelevance of
refinements. Consider extending both source and target languages of $\R$ with
usage-aware `subset' dependent pairs
\[
\inferrule{\Gamma \vdash A \type \\ \Gamma, A \vdash B \type}{\Gamma \vdash \{A \mid B\} \type}
\]
in such a way that $\MRepr$ and $\R$ preserve them, but the extraction step
erases the right component, i.e. $|\{A \mid B\}| = |A|$, $|(x, y)| = |x|$ and
$|\pi_1 x| = |x|$. This can be implemented using quantitative type
theory for example. Suppose we have an inductive family $G = \mta{data}_I\ S_G\
\gamma_G$ over some index type $I$, and an inductive type $F = \mta{data}\ S_F\
\gamma_F$ such that $G$ is represented by a refinement $r : F \to I$, meaning
\[
    \gamma_G = (\lambda i.\ \{ f : F \mid r\ f \equiv_I i \}, \alpha, \kappa) \,.
\]
Then, we can construct computationally irrelevant functions
\begin{align*}
&\begin{aligned}
&\mta{forget}_i : G\ i \to F \\
&\mta{forget}_i = \lambda g.\ \pi_1\ (\mta{repr}\ g)
\end{aligned} \quad \begin{aligned}
&\mta{remember} : (f : F) \to G\ (r\ f) \\
&\mta{remember} = \lambda x.\ \mta{unrepr}\ (x, \mta{refl}) \,.
\end{aligned}
\end{align*}
By reasoning similar to \cref{thm:repr-inj}, $|\R\ \mta{forget}_i| = |\R\
\mta{remember}| = \Pid$.
